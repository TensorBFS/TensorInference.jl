<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public · TensorInference.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://TensorBFS.github.io/TensorInference.jl/api/public/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="TensorInference.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TensorInference.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../background/">Background</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../generated/asia/main/">Asia network</a></li></ul></li><li><a class="tocitem" href="../../uai-file-formats/">UAI file formats</a></li><li><a class="tocitem" href="../../performance/">Performance tips</a></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Public</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Modules"><span>Modules</span></a></li><li><a class="tocitem" href="#Types"><span>Types</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li></ul></li><li><a class="tocitem" href="../internal/">Internal</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Public</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/api/public.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Public-API"><a class="docs-heading-anchor" href="#Public-API">Public API</a><a id="Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#Public-API" title="Permalink"></a></h1><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p><a href="#Modules">Modules</a></p><ul><li><a href="#TensorInference"><code>TensorInference</code></a></li></ul><p><a href="#Types">Types</a></p><ul><li><a href="#OMEinsumContractionOrders.GreedyMethod"><code>OMEinsumContractionOrders.GreedyMethod</code></a></li><li><a href="#OMEinsumContractionOrders.KaHyParBipartite"><code>OMEinsumContractionOrders.KaHyParBipartite</code></a></li><li><a href="#OMEinsumContractionOrders.MergeGreedy"><code>OMEinsumContractionOrders.MergeGreedy</code></a></li><li><a href="#OMEinsumContractionOrders.MergeVectors"><code>OMEinsumContractionOrders.MergeVectors</code></a></li><li><a href="#OMEinsumContractionOrders.SABipartite"><code>OMEinsumContractionOrders.SABipartite</code></a></li><li><a href="#OMEinsumContractionOrders.TreeSA"><code>OMEinsumContractionOrders.TreeSA</code></a></li><li><a href="#TensorInference.MMAPModel"><code>TensorInference.MMAPModel</code></a></li><li><a href="#TensorInference.RescaledArray"><code>TensorInference.RescaledArray</code></a></li><li><a href="#TensorInference.TensorNetworkModel"><code>TensorInference.TensorNetworkModel</code></a></li><li><a href="#TensorInference.UAIInstance"><code>TensorInference.UAIInstance</code></a></li></ul><p><a href="#Functions">Functions</a></p><ul><li><a href="#OMEinsumContractionOrders.contraction_complexity"><code>OMEinsumContractionOrders.contraction_complexity</code></a></li><li><a href="#TensorInference.get_cards"><code>TensorInference.get_cards</code></a></li><li><a href="#TensorInference.get_vars"><code>TensorInference.get_vars</code></a></li><li><a href="#TensorInference.log_probability"><code>TensorInference.log_probability</code></a></li><li><a href="#TensorInference.marginals"><code>TensorInference.marginals</code></a></li><li><a href="#TensorInference.maximum_logp"><code>TensorInference.maximum_logp</code></a></li><li><a href="#TensorInference.most_probable_config"><code>TensorInference.most_probable_config</code></a></li><li><a href="#TensorInference.probability"><code>TensorInference.probability</code></a></li><li><a href="#TensorInference.read_evidence_file"><code>TensorInference.read_evidence_file</code></a></li><li><a href="#TensorInference.read_instance"><code>TensorInference.read_instance</code></a></li><li><a href="#TensorInference.read_model_file"><code>TensorInference.read_model_file</code></a></li><li><a href="#TensorInference.read_solution_file"><code>TensorInference.read_solution_file</code></a></li><li><a href="#TensorInference.read_td_file"><code>TensorInference.read_td_file</code></a></li><li><a href="#TensorInference.sample"><code>TensorInference.sample</code></a></li><li><a href="#TensorInference.set_evidence!"><code>TensorInference.set_evidence!</code></a></li></ul><h2 id="Modules"><a class="docs-heading-anchor" href="#Modules">Modules</a><a id="Modules-1"></a><a class="docs-heading-anchor-permalink" href="#Modules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="TensorInference" href="#TensorInference"><code>TensorInference</code></a> — <span class="docstring-category">Module</span></header><section><div><p>Main module for <code>TensorInference.jl</code> – A toolbox for probabilistic inference using contraction of tensor networks.</p><p><strong>Exports</strong></p><ul><li><a href="#OMEinsumContractionOrders.GreedyMethod"><code>GreedyMethod</code></a></li><li><a href="#OMEinsumContractionOrders.KaHyParBipartite"><code>KaHyParBipartite</code></a></li><li><a href="#TensorInference.MMAPModel"><code>MMAPModel</code></a></li><li><a href="#OMEinsumContractionOrders.MergeGreedy"><code>MergeGreedy</code></a></li><li><a href="#OMEinsumContractionOrders.MergeVectors"><code>MergeVectors</code></a></li><li><a href="#TensorInference.RescaledArray"><code>RescaledArray</code></a></li><li><a href="#OMEinsumContractionOrders.SABipartite"><code>SABipartite</code></a></li><li><a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a></li><li><a href="#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a></li><li><a href="#TensorInference.UAIInstance"><code>UAIInstance</code></a></li><li><a href="#OMEinsumContractionOrders.contraction_complexity"><code>contraction_complexity</code></a></li><li><a href="#TensorInference.get_cards"><code>get_cards</code></a></li><li><a href="#TensorInference.get_vars"><code>get_vars</code></a></li><li><a href="#TensorInference.log_probability"><code>log_probability</code></a></li><li><a href="#TensorInference.marginals"><code>marginals</code></a></li><li><a href="#TensorInference.maximum_logp"><code>maximum_logp</code></a></li><li><a href="#TensorInference.most_probable_config"><code>most_probable_config</code></a></li><li><a href="#TensorInference.probability"><code>probability</code></a></li><li><a href="#TensorInference.read_evidence_file"><code>read_evidence_file</code></a></li><li><a href="#TensorInference.read_instance"><code>read_instance</code></a></li><li><a href="#TensorInference.read_model_file"><code>read_model_file</code></a></li><li><a href="#TensorInference.read_solution_file"><code>read_solution_file</code></a></li><li><a href="#TensorInference.read_td_file"><code>read_td_file</code></a></li><li><a href="#TensorInference.sample"><code>sample</code></a></li><li><a href="#TensorInference.set_evidence!"><code>set_evidence!</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/TensorInference.jl#L1-L7">source</a></section></article><h2 id="Types"><a class="docs-heading-anchor" href="#Types">Types</a><a id="Types-1"></a><a class="docs-heading-anchor-permalink" href="#Types" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.GreedyMethod" href="#OMEinsumContractionOrders.GreedyMethod"><code>OMEinsumContractionOrders.GreedyMethod</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GreedyMethod{MT}
GreedyMethod(; method=MinSpaceOut(), nrepeat=10)</code></pre><p>The fast but poor greedy optimizer. Input arguments are</p><ul><li><code>method</code> is <code>MinSpaceDiff()</code> or <code>MinSpaceOut</code>.<ul><li><code>MinSpaceOut</code> choose one of the contraction that produces a minimum output tensor size,</li><li><code>MinSpaceDiff</code> choose one of the contraction that decrease the space most.</li></ul></li><li><code>nrepeat</code> is the number of repeatition, returns the best contraction order.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.KaHyParBipartite" href="#OMEinsumContractionOrders.KaHyParBipartite"><code>OMEinsumContractionOrders.KaHyParBipartite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KaHyParBipartite{RT,IT,GM}
KaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),
    max_group_size=40, greedy_config=GreedyMethod())</code></pre><p>Optimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>imbalances</code> is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>greedy_config</code> is a greedy optimizer.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li><li><a href="https://arxiv.org/abs/2103.03074">Simulating the Sycamore quantum supremacy circuits</a></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.MergeGreedy" href="#OMEinsumContractionOrders.MergeGreedy"><code>OMEinsumContractionOrders.MergeGreedy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MergeGreedy &lt;: CodeSimplifier
MergeGreedy(; threshhold=-1e-12)</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the <code>threshhold</code>).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.MergeVectors" href="#OMEinsumContractionOrders.MergeVectors"><code>OMEinsumContractionOrders.MergeVectors</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MergeVectors &lt;: CodeSimplifier
MergeVectors()</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.SABipartite" href="#OMEinsumContractionOrders.SABipartite"><code>OMEinsumContractionOrders.SABipartite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SABipartite{RT,BT}
SABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000
    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><ul><li><code>size_dict</code>, a dictionary that specifies leg dimensions,</li><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>βs</code> is a list of inverse temperature <code>1/T</code>,</li><li><code>niters</code> is the number of iteration in each temperature,</li><li><code>ntrials</code> is the number of repetition (with different random seeds),</li><li><code>greedy_config</code> configures the greedy method,</li><li><code>initializer</code>, the partition configuration initializer, one can choose <code>:random</code> or <code>:greedy</code> (slow but better).</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.TreeSA" href="#OMEinsumContractionOrders.TreeSA"><code>OMEinsumContractionOrders.TreeSA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TreeSA{RT,IT,GM}
TreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,
    sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree.</p><ul><li><code>sc_target</code> is the target space complexity,</li><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>sc_weight</code> is the relative importance factor of space complexity in the loss compared with the time complexity.</li><li><code>rw_weight</code> is the relative importance factor of memory read and write in the loss compared with the time complexity.</li><li><code>initializer</code> specifies how to determine the initial configuration, it can be <code>:greedy</code> or <code>:random</code>. If it is using <code>:greedy</code> method to generate the initial configuration, it also uses two extra arguments <code>greedy_method</code> and <code>greedy_nrepeat</code>.</li><li><code>nslices</code> is the number of sliced legs, default is 0.</li><li><code>fixed_slices</code> is a vector of sliced legs, default is <code>[]</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.MMAPModel" href="#TensorInference.MMAPModel"><code>TensorInference.MMAPModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct MMAPModel{LT, AT&lt;:AbstractArray}</code></pre><p>Computing the most likely assignment to the query variables,  Xₘ ⊆ X after marginalizing out the remaining variables Xₛ = X \ Xₘ.</p><p class="math-container">\[{\rm MMAP}(X_i|E=e) = \arg \max_{X_M} \sum_{X_S} \prod_{F} f(x_M, x_S, e)\]</p><p><strong>Fields</strong></p><ul><li><code>vars</code> is the query variables in the tensor network.</li><li><code>code</code> is the tropical tensor network contraction pattern.</li><li><code>tensors</code> is the tensors fed into the tensor network.</li><li><code>clusters</code> is the clusters, each element of this cluster is a <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a> instance for marginalizing certain variables.</li><li><code>fixedvertices</code> is a dictionary to specifiy degree of freedoms fixed to certain values, which should not have overlap with the query variables.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/mmap.jl#L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.RescaledArray" href="#TensorInference.RescaledArray"><code>TensorInference.RescaledArray</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct RescaledArray{T, N, AT&lt;:AbstractArray{T, N}} &lt;: AbstractArray{T, N}</code></pre><pre><code class="nohighlight hljs">RescaledArray(α, T) -&gt; RescaledArray</code></pre><p>An array data type with a log-prefactor, and a l∞-normalized storage, i.e. the maximum element in a tensor is 1. This tensor type can avoid the potential underflow/overflow of numbers in a tensor network. The constructor <code>RescaledArray(α, T)</code> creates a rescaled array that equal to <code>exp(α) * T</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/RescaledArray.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.TensorNetworkModel" href="#TensorInference.TensorNetworkModel"><code>TensorInference.TensorNetworkModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct TensorNetworkModel{LT, ET, MT&lt;:AbstractArray}</code></pre><p>Probabilistic modeling with a tensor network.</p><p><strong>Fields</strong></p><ul><li><code>vars</code> is the degree of freedoms in the tensor network.</li><li><code>code</code> is the tensor network contraction pattern.</li><li><code>tensors</code> is the tensors fed into the tensor network.</li><li><code>fixedvertices</code> is a dictionary to specifiy degree of freedoms fixed to certain values.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.UAIInstance" href="#TensorInference.UAIInstance"><code>TensorInference.UAIInstance</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct UAIInstance{ET, FT&lt;:(TensorInference.Factor{ET})}</code></pre><p><strong>Fields</strong></p><ul><li><p><code>nvars</code> is the number of variables,</p></li><li><p><code>nclique</code> is the number of cliques,</p></li><li><p><code>cards</code> is a vector of cardinalities for variables,</p></li><li><p><code>factors</code> is a vector of factors,</p></li><li><p><code>obsvars</code> is a vector of observed variables,</p></li><li><p><code>obsvals</code> is a vector of observed values,</p></li><li><p><code>queryvars</code> is a vector of query variables,</p></li><li><p><code>reference_solution</code> is a vector with the reference solution.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L17">source</a></section></article><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="OMEinsumContractionOrders.contraction_complexity" href="#OMEinsumContractionOrders.contraction_complexity"><code>OMEinsumContractionOrders.contraction_complexity</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">contraction_complexity(tensor_network)</code></pre><p>Returns the contraction complexity of a tensor newtork model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L216-L220">source</a></section><section><div><pre><code class="nohighlight hljs">contraction_complexity(eincode, size_dict) -&gt; ContractionComplexity</code></pre><p>Returns the time, space and read-write complexity of the einsum contraction. The returned object contains 3 fields:</p><ul><li>time complexity <code>tc</code> defined as <code>log2(number of element-wise multiplications)</code>.</li><li>space complexity <code>sc</code> defined as <code>log2(size of the maximum intermediate tensor)</code>.</li><li>read-write complexity <code>rwc</code> defined as <code>log2(the number of read-write operations)</code>.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.get_cards" href="#TensorInference.get_cards"><code>TensorInference.get_cards</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_cards(tn::TensorNetworkModel; fixedisone) -&gt; Vector
</code></pre><p>Get the cardinalities of variables in this tensor network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L184">source</a></section><section><div><pre><code class="language-julia hljs">get_cards(mmap::MMAPModel; fixedisone) -&gt; Vector
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/mmap.jl#L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.get_vars" href="#TensorInference.get_vars"><code>TensorInference.get_vars</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_vars(tn::TensorNetworkModel) -&gt; Vector
</code></pre><p>Get the variables in this tensor network, they are also known as legs, labels, or degree of freedoms.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L177">source</a></section><section><div><pre><code class="language-julia hljs">get_vars(mmap::MMAPModel) -&gt; Vector
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/mmap.jl#L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.log_probability" href="#TensorInference.log_probability"><code>TensorInference.log_probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">log_probability(
    tn::TensorNetworkModel,
    config::Union{Dict, AbstractVector}
) -&gt; Real
</code></pre><p>Evaluate the log probability of <code>config</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L196">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.marginals" href="#TensorInference.marginals"><code>TensorInference.marginals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">marginals(
    tn::TensorNetworkModel;
    usecuda,
    rescale
) -&gt; Vector
</code></pre><p>Returns the marginal probability distribution of variables. One can use <code>get_vars(tn)</code> to get the full list of variables in this tensor network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/mar.jl#L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.maximum_logp" href="#TensorInference.maximum_logp"><code>TensorInference.maximum_logp</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">maximum_logp(
    tn::TensorNetworkModel;
    usecuda
) -&gt; AbstractArray{&lt;:Real}
</code></pre><p>Returns an output array containing largest log-probabilities.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/map.jl#L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.most_probable_config" href="#TensorInference.most_probable_config"><code>TensorInference.most_probable_config</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">most_probable_config(
    tn::TensorNetworkModel;
    usecuda
) -&gt; Tuple{Real, Vector}
</code></pre><p>Returns the largest log-probability and the most probable configuration.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/map.jl#L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.probability" href="#TensorInference.probability"><code>TensorInference.probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probability(
    tn::TensorNetworkModel;
    usecuda,
    rescale
) -&gt; AbstractArray
</code></pre><p>Contract the tensor network and return a probability array with its rank specified in the contraction code <code>tn.code</code>. The returned array may not be l1-normalized even if the total probability is l1-normalized, because the evidence <code>tn.fixedvertices</code> may not be empty.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L206">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.read_evidence_file" href="#TensorInference.read_evidence_file"><code>TensorInference.read_evidence_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_evidence_file(
    evidence_filepath::AbstractString
) -&gt; Tuple{Vector{Int64}, Vector{Int64}}
</code></pre><p>Return the observed variables and values in <code>evidence_filepath</code>. If the passed file path is an empty string, return empty vectors.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/utils.jl#L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.read_instance" href="#TensorInference.read_instance"><code>TensorInference.read_instance</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_instance(
    model_filepath::AbstractString;
    evidence_filepath,
    query_filepath,
    solution_filepath,
    eltype
) -&gt; UAIInstance
</code></pre><p>Read a UAI problem instance from a file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/utils.jl#L228">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.read_model_file" href="#TensorInference.read_model_file"><code>TensorInference.read_model_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_model_file(
    model_filepath;
    factor_eltype
) -&gt; Tuple{Int64, Vector{Int64}, Int64, Any}
</code></pre><p>Parse the problem instance found in <code>model_filepath</code> defined in the UAI model format.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/utils.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.read_solution_file" href="#TensorInference.read_solution_file"><code>TensorInference.read_solution_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_solution_file(
    solution_filepath::AbstractString;
    factor_eltype
) -&gt; Union{Float64, Vector{Vector{Float64}}, Vector{Int64}}
</code></pre><p>Return the solution in <code>solution_filepath</code>. Returns an empty vector if the extension is not supported.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/utils.jl#L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.read_td_file" href="#TensorInference.read_td_file"><code>TensorInference.read_td_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_td_file(
    td_filepath::AbstractString
) -&gt; Tuple{Int64, Int64, Int64, Vector{Vector{Int64}}, Vector{Vector{Int64}}}
</code></pre><p>Parse a tree decomposition instance described the PACE format.</p><p>The PACE file format is defined in: https://pacechallenge.org/2017/treewidth/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/utils.jl#L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.sample" href="#TensorInference.sample"><code>TensorInference.sample</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sample(
    tn::TensorNetworkModel,
    n::Int64;
    usecuda
) -&gt; Matrix{Int64}
</code></pre><p>Generate samples from a tensor network based probabilistic model. Returns a vector of vector, each element being a configurations defined on <code>get_vars(tn)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>tn</code> is the tensor network model.</li><li><code>n</code> is the number of samples to be returned.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/sampling.jl#L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TensorInference.set_evidence!" href="#TensorInference.set_evidence!"><code>TensorInference.set_evidence!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">set_evidence!(
    uai::UAIInstance,
    pairs::Pair{Int64}...
) -&gt; UAIInstance
</code></pre><p>Set the evidence of an UAI instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/470a881583cf26e3d21a609b98b729970565276d/src/Core.jl#L57">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../performance/">« Performance tips</a><a class="docs-footer-nextpage" href="../internal/">Internal »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 13 July 2023 12:52">Thursday 13 July 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
