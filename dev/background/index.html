<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · TensorInference.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://TensorBFS.github.io/TensorInference.jl/background/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="TensorInference.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">TensorInference.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#Probabilistic-graphical-models"><span>Probabilistic graphical models</span></a></li><li><a class="tocitem" href="#The-inference-tasks"><span>The inference tasks</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../generated/asia/main/">Asia network</a></li></ul></li><li><a class="tocitem" href="../uai-file-formats/">UAI file formats</a></li><li><a class="tocitem" href="../performance/">Performance tips</a></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../api/public/">Public</a></li><li><a class="tocitem" href="../api/internal/">Internal</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/background.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h1><p><em>TensorInference</em> implements efficient methods to perform Bayesian inference in <em>probabilistic graphical models</em>, such as Bayesian Networks or Markov random fields.</p><h2 id="Probabilistic-graphical-models"><a class="docs-heading-anchor" href="#Probabilistic-graphical-models">Probabilistic graphical models</a><a id="Probabilistic-graphical-models-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-graphical-models" title="Permalink"></a></h2><p>Probabilistic graphical models (PGMs) capture the mathematical modeling of reasoning in the presence of uncertainty. Bayesian networks and Markov random fields are popular types of PGMs. Consider the following Bayesian network known as the <em>ASIA network</em> <sup class="footnote-reference"><a id="citeref-lauritzen1988local" href="#footnote-lauritzen1988local">[lauritzen1988local]</a></sup>. </p><p><img src="../asia-bayesian-network.svg" alt/></p><table><tr><th style="text-align: center"><strong>Random variable</strong></th><th style="text-align: left"><strong>Meaning</strong></th></tr><tr><td style="text-align: center"><span>$A$</span></td><td style="text-align: left">Recent trip to Asia</td></tr><tr><td style="text-align: center"><span>$T$</span></td><td style="text-align: left">Patient has tuberculosis</td></tr><tr><td style="text-align: center"><span>$S$</span></td><td style="text-align: left">Patient is a smoker</td></tr><tr><td style="text-align: center"><span>$L$</span></td><td style="text-align: left">Patient has lung cancer</td></tr><tr><td style="text-align: center"><span>$B$</span></td><td style="text-align: left">Patient has bronchitis</td></tr><tr><td style="text-align: center"><span>$E$</span></td><td style="text-align: left">Patient hast <span>$T$</span> and/or <span>$L$</span></td></tr><tr><td style="text-align: center"><span>$X$</span></td><td style="text-align: left">Chest X-Ray is positive</td></tr><tr><td style="text-align: center"><span>$D$</span></td><td style="text-align: left">Patient has dyspnoea</td></tr></table><p>The ASIA network corresponds a simplified example from the context of medical diagnosis that describes the probabilistic relationships between different random variables corresponding to possible diseases, symptoms, risk factors and test results. It consists of a graph <span>$G = (\bm{V},\mathcal{E})$</span> and a probability distribution <span>$P(\bm{V})$</span> where <span>$G$</span> is a directed acyclic graph, <span>$\bm{V}$</span> is the set of variables and <span>$\mathcal{E}$</span> is the set of edges connecting the variables. We assume all variables to be discrete. Each variable <span>$V$</span> is quantified with a <em>conditional probability distribution</em> <span>$P(V \mid pa(V))$</span> where <span>$pa(V)$</span> are the parents of <span>$V$</span>. These conditional probability distributions together with the graph <span>$G$</span> induce a <em>joint probability distribution</em> over <span>$P(\bm{V})$</span>, given by</p><p class="math-container">\[P(\bm{V}) = \prod_{V\in\bm{V}} P(V \mid pa(V)).\]</p><h2 id="The-inference-tasks"><a class="docs-heading-anchor" href="#The-inference-tasks">The inference tasks</a><a id="The-inference-tasks-1"></a><a class="docs-heading-anchor-permalink" href="#The-inference-tasks" title="Permalink"></a></h2><p>Each task is performed with respect to a graphical model, denoted as <span>$\mathcal{M} = \{\bm{V}, \bm{D}, \bm{\phi}\}$</span>, where:</p><p><span>$\bm{V} = \{ V_1 , V_2 , \dots , V_N \}$</span> is the set of the model’s variables</p><p><span>$\bm{D} = \{ D_{V_1} , D_{V_2} , \dots , D_{V_N} \}$</span> is the set of discrete domains for each variable, and</p><p><span>$\bm{\phi} = \{ \phi_1 , \phi_2 , \dots , \phi_N \}$</span> is the set of factors that define the joint probability distribution of the model.</p><p>The variable set <span>$\bm{V}$</span> can be further partitioned into two subsets: the evidence variables <span>$\bm{E}$</span> and the remaining variables <span>$\bm{V}^\prime = \bm{V} \setminus \bm{E}$</span>. Furthermore, within the set <span>$\bm{V}^\prime$</span>, the subset <span>$\bm{Q}$</span> denotes the query variables. These are the variables for which we aim to estimate or infer values.</p><p><img src="../the-inference-tasks.svg" alt/></p><h3 id="Probability-of-evidence-(PR)"><a class="docs-heading-anchor" href="#Probability-of-evidence-(PR)">Probability of evidence (PR)</a><a id="Probability-of-evidence-(PR)-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-of-evidence-(PR)" title="Permalink"></a></h3><p>Computing the partition function (ie. normalizing constant) or probability of evidence:</p><p class="math-container">\[PR(\bm{V}^{\prime} \mid \bm{E}=\bm{e}) = \sum_{V^{\prime} \in \bm{V}^{\prime}} \prod_{\phi \in \bm{\phi}} \phi(V^{\prime},\bm{e})\]</p><p>This task involves calculating the probability of the observed evidence, which can be useful for model comparison or anomaly detection. This involves summing the joint probability over all possible states of the unobserved variables in the model, given some observed variables. This is a fundamental task in Bayesian statistics and is often used as a stepping stone for other types of inference.&quot;</p><h3 id="Marginal-inference-(MAR):"><a class="docs-heading-anchor" href="#Marginal-inference-(MAR):">Marginal inference (MAR):</a><a id="Marginal-inference-(MAR):-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-inference-(MAR):" title="Permalink"></a></h3><p>Computing the marginal probability distribution over all variables given evidence:</p><p class="math-container">\[MAR(V_i \mid \bm{E}=\bm{e}) = \frac{ \sum_{V^{\prime\prime} \in \bm{V}^{\prime}
\setminus V_i} \prod_{\phi \in \bm{\phi}} \phi(V^{\prime\prime},\bm{e}) }{
    PR(\bm{V}^{\prime} \mid \bm{E}=\bm{e}) }\]</p><p>This task involves computing the marginal probability of a subset of variables, integrating out the others. In other words, it computes the probability distribution of some variables of interest regardless of the states of all other variables. This is useful when we&#39;re interested in the probabilities of some specific variables in the model, but not the entire model.</p><h3 id="Maximum-a-Posteriori-Probability-estimation-(MAP)"><a class="docs-heading-anchor" href="#Maximum-a-Posteriori-Probability-estimation-(MAP)">Maximum a Posteriori Probability estimation (MAP)</a><a id="Maximum-a-Posteriori-Probability-estimation-(MAP)-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-a-Posteriori-Probability-estimation-(MAP)" title="Permalink"></a></h3><p>Computing the most likely assignment to all variables given evidence:</p><p class="math-container">\[MAP(V_i \mid \bm{E}=\bm{e}) = \arg \max_{V^{\prime} \in \bm{V}^{\prime}}
\prod_{\phi \in \bm{\phi}} \phi(V^{\prime},\bm{e})\]</p><p>In the MAP task, given some observed variables, the goal is to find the most probable assignment of values to some subset of the unobserved variables. It provides the states of variables that maximize the posterior probability given some observed evidence. This is often used when we want the most likely explanation or prediction according to the model.</p><h3 id="Marginal-Maximum-a-Posteriori-(MMAP)"><a class="docs-heading-anchor" href="#Marginal-Maximum-a-Posteriori-(MMAP)">Marginal Maximum a Posteriori (MMAP)</a><a id="Marginal-Maximum-a-Posteriori-(MMAP)-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-Maximum-a-Posteriori-(MMAP)" title="Permalink"></a></h3><p>Computing the most likely assignment to the query variables, <span>$\bm{Q} \subset \bm{V}^{\prime}$</span> after marginalizing out the remaining variables <span>$\bm{Z} = \bm{V}^{\prime} \setminus \bm{Q}$</span>, also known as <em>hidden</em> or <em>latent</em> variables:</p><p class="math-container">\[MMAP(V_i \mid \bm{E}=e) = \arg \max_{Q \in \bm{Q}} \sum_{Z \in \bm{Z}}
\prod_{\phi \in \bm{\phi}} \phi(Q, Z, e)\]</p><p>This task is essentially a combination of the MAR and MAP tasks. The MMAP task involves finding the most probable assignment (the MAP estimate) for a subset of the variables, while marginalizing over (summing out) the remaining variables. This task is useful when we want to know the most likely state of some variables, but there&#39;s some uncertainty over others that we need to average out.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-lauritzen1988local"><a class="tag is-link" href="#citeref-lauritzen1988local">lauritzen1988local</a>Steffen L Lauritzen and David J Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, 50(2):157–194, 1988.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../generated/asia/main/">Asia network »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 13 July 2023 12:52">Thursday 13 July 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
