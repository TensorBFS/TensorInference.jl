var documenterSearchIndex = {"docs":
[{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"EditURL = \"https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/generated/asia/main.jl\"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"using TensorInference","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Load the model that detailed in the README and asia.uai.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"instance = read_instance(pkgdir(TensorInference, \"examples\", \"asia\", \"asia.uai\"))\ntnet = TensorNetworkModel(instance)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"TensorNetworkModel{Int64, OMEinsum.DynamicNestedEinsum{Int64}, Array{Float64}}\nvariables: 1, 2, 3, 4, 5, 6, 7, 8\ncontraction time = 2^6.087, space = 2^2.0, read-write = 2^7.14","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get the probabilities (PR)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"probability(tnet)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"exp(-2.220446049250313e-16) * fill(1.0)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get the marginal probabilities (MAR)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"marginals(tnet) .|> first","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8-element Vector{Float64}:\n 0.009999999999999998\n 0.010399999999999998\n 0.5\n 0.05500000000000001\n 0.44999999999999996\n 0.064828\n 0.11029004\n 0.43597060000000004","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"The corresponding variables are","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"get_vars(tnet)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Set the evidence variables \"X-ray\" (7) to be positive.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"set_evidence!(instance, 7=>0)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"UAIInstance(nvars = 8, nclique = 8)\n variables :\n  1 of size 2\n  2 of size 2\n  3 of size 2\n  4 of size 2\n  5 of size 2\n  6 of size 2\n  7 of size 2\n  8 of size 2\n factors : \n  Factor(1), size = (2,)\n  Factor(1, 2), size = (2, 2)\n  Factor(3), size = (2,)\n  Factor(3, 4), size = (2, 2)\n  Factor(3, 5), size = (2, 2)\n  Factor(2, 4, 6), size = (2, 2, 2)\n  Factor(6, 7), size = (2, 2)\n  Factor(5, 6, 8), size = (2, 2, 2)\n reference_solution : Vector{Float64}[]","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Since the evidence variable may change the contraction order, we re-compute the tensor network.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"tnet = TensorNetworkModel(instance)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"TensorNetworkModel{Int64, OMEinsum.DynamicNestedEinsum{Int64}, Array{Float64}}\nvariables: 1, 2, 3, 4, 5, 6, 7 (evidence → 0), 8\ncontraction time = 2^6.0, space = 2^2.0, read-write = 2^7.066","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get the maximum log-probabilities (MAP)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"maximum_logp(tnet)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"0-dimensional Array{Float64, 0}:\n-3.65222179200233","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"To sample from the probability model","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"sample(tnet, 10)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8×10 Matrix{Int64}:\n 1  1  1  1  1  1  1  1  1  1\n 1  1  1  1  1  1  1  1  1  1\n 0  0  0  0  0  1  0  0  0  1\n 1  1  0  0  1  1  1  0  0  1\n 1  0  0  1  0  0  1  1  1  0\n 1  1  0  0  1  1  1  0  0  1\n 0  0  0  0  0  0  0  0  0  0\n 1  0  0  1  1  0  1  0  0  0","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get not only the maximum log-probability, but also the most probable conifguration In the most probable configuration, the most probable one is the patient smoke (3) and has lung cancer (4)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"logp, cfg = most_probable_config(tnet)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-3.65222179200233, [1, 1, 0, 0, 0, 0, 0, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get the maximum log-probabilities (MMAP) To get the probability of lung cancer, we need to marginalize out other variables.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"mmap = MMAPModel(instance; queryvars=[4,7])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"MMAPModel{Int64, Array{Float64}}\nvariables: 4, 7 (evidence → 0)\nquery variables: [[1, 2, 6, 5, 3, 8]]\ncontraction time = 2^6.0, space = 2^2.0, read-write = 2^7.0","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"We get the most probable configurations on [4, 7]","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"most_probable_config(mmap)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-2.8754627318176693, [1, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"The total probability of having lung cancer is roughly half.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"log_probability(mmap, [1, 0]), log_probability(mmap, [0, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-2.8754627318176693, -2.9206248010671856)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"This page was generated using Literate.jl.","category":"page"},{"location":"performance/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance/#Optimize-contraction-orders","page":"Performance Tips","title":"Optimize contraction orders","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Let us use the independent set problem on 3-regular graphs as an example.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> using TensorInference, Artifacts, Pkg\n\njulia> Pkg.ensure_artifact_installed(\"uai2014\", pkgdir(TensorInference, \"test\", \"Artifacts.toml\"));\n\njulia> function get_instance_filepaths(problem_name::AbstractString, task::AbstractString)\n        model_filepath = joinpath(artifact\"uai2014\", task, problem_name * \".uai\")\n        evidence_filepath = joinpath(artifact\"uai2014\", task, problem_name * \".uai.evid\")\n        solution_filepath = joinpath(artifact\"uai2014\", task, problem_name * \".uai.\" * task)\n        return model_filepath, evidence_filepath, solution_filepath\n    end\n\njulia> model_filepath, evidence_filepath, solution_filepath = get_instance_filepaths(\"Promedus_14\", \"MAR\")\n\njulia> instance = read_instance(model_filepath; evidence_filepath, solution_filepath)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Next, we select the tensor network contraction order optimizer.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> optimizer = TreeSA(ntrials = 1, niters = 5, βs = 0.1:0.1:100)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Here, we choose the local search based TreeSA algorithm, which often finds the smallest time/space complexity and supports slicing. One can type ?TreeSA in a Julia REPL for more information about how to configure the hyper-parameters of the TreeSA method,  while the detailed algorithm explanation is in arXiv: 2108.05665. Alternative tensor network contraction order optimizers include","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"GreedyMethod (default, fastest in searching speed but worst in contraction complexity)\nKaHyParBipartite\nSABipartite","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> tn = TensorNetworkModel(instance; optimizer)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"The returned object tn contains a field code that specifies the tensor network with optimized contraction order. To check the contraction complexity, please type","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> contraction_complexity(problem)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"The returned object contains log2 values of the number of multiplications, the number elements in the largest tensor during contraction and the number of read-write operations to tensor elements.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> p1 = probability(tn)","category":"page"},{"location":"performance/#Slicing-technique","page":"Performance Tips","title":"Slicing technique","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"For large scale applications, it is also possible to slice over certain degrees of freedom to reduce the space complexity, i.e. loop and accumulate over certain degrees of freedom so that one can have a smaller tensor network inside the loop due to the removal of these degrees of freedom. In the TreeSA optimizer, one can set nslices to a value larger than zero to turn on this feature.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> tn = TensorNetworkModel(instance; optimizer=TreeSA());\n\njulia> contraction_complexity(tn)\n(20.856518235241687, 16.0, 18.88208476145812)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"As a comparision we slice over 5 degrees of freedom, which can reduce the space complexity by at most 5. In this application, the slicing achieves the largest possible space complexity reduction 5, while the time and read-write complexity are only increased by less than 1, i.e. the peak memory usage is reduced by a factor 32, while the (theoretical) computing time is increased by at a factor  2.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> tn = TensorNetworkModel(instance; optimizer=TreeSA(nslices=5));\n\njulia> timespacereadwrite_complexity(problem)\n(21.134967710592804, 11.0, 19.84529401927876)","category":"page"},{"location":"performance/#GEMM-for-Tropical-numbers","page":"Performance Tips","title":"GEMM for Tropical numbers","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"No extra effort is required to enjoy the BLAS level speed provided by TropicalGEMM. The benchmark in the TropicalGEMM repo shows this performance is close to the theoretical optimal value. Its implementation on GPU is under development in Github repo CuTropicalGEMM.jl as a part of Open Source Promotion Plan summer program.","category":"page"},{"location":"performance/#Working-with-GPUs","page":"Performance Tips","title":"Working with GPUs","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"To upload the computation to GPU, you just add using CUDA before calling the solve function, and set the keyword argument usecuda to true.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> using CUDA\n[ Info: OMEinsum loaded the CUDA module successfully\n\njulia> marginals(tn; usecuda = true)","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Functions support usecuda keyword argument includes","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"probability\nlog_probability\nmarginals\nmost_probable_config","category":"page"},{"location":"performance/#Benchmarks","page":"Performance Tips","title":"Benchmarks","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Please check our paper (link to be added).","category":"page"},{"location":"generated/asia/README/#The-\"Asia\"-Bayesian-network","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"","category":"section"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"Please check the Julia code asia.jl.","category":"page"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"The variables and factors for the asia model is described in the asia.uai file. The UAI file format is detailed in: https://personal.utdallas.edu/~vibhav.gogate/uai16-evaluation/uaiformat.html","category":"page"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"The meanings of variables and factors as listed bellow.","category":"page"},{"location":"generated/asia/README/#Variables","page":"The \"Asia\" Bayesian network","title":"Variables","text":"","category":"section"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"index 0 is mapped to yes, 1 is mapped to no.","category":"page"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"visit to Asia (a)\ntuberculosis (t)\nsmoking (s)\nlung cancer (l)\nbronchitis (b)\neither tub. or lung cancer (e)\npositive X-ray (x)\ndyspnoea (d)","category":"page"},{"location":"generated/asia/README/#Factors","page":"The \"Asia\" Bayesian network","title":"Factors","text":"","category":"section"},{"location":"generated/asia/README/","page":"The \"Asia\" Bayesian network","title":"The \"Asia\" Bayesian network","text":"p(a)\np(t|a)\np(s)\np(l|s)\np(b|s)\np(e|l,t)\np(x|e)\np(d|e,b)","category":"page"},{"location":"ref/#References","page":"References","title":"References","text":"","category":"section"},{"location":"ref/#TensorInference","page":"References","title":"TensorInference","text":"","category":"section"},{"location":"ref/","page":"References","title":"References","text":"Modules = [TensorInference]\nOrder   = [:function, :type]\nPrivate = false","category":"page"},{"location":"ref/#OMEinsumContractionOrders.contraction_complexity-Tuple{TensorNetworkModel}","page":"References","title":"OMEinsumContractionOrders.contraction_complexity","text":"contraction_complexity(tensor_network)\n\nReturns the contraction complexity of a tensor newtork model.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.get_cards-Tuple{MMAPModel}","page":"References","title":"TensorInference.get_cards","text":"get_cards(mmap::MMAPModel; fixedisone) -> Vector\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.get_cards-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.get_cards","text":"get_cards(tn::TensorNetworkModel; fixedisone) -> Vector\n\n\nGet the cardinalities of variables in this tensor network.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.get_vars-Tuple{MMAPModel}","page":"References","title":"TensorInference.get_vars","text":"get_vars(mmap::MMAPModel) -> Vector\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.get_vars-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.get_vars","text":"get_vars(tn::TensorNetworkModel) -> Vector\n\n\nGet the variables in this tensor network, they are also known as legs, labels, or degree of freedoms.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.log_probability-Tuple{TensorNetworkModel, Union{Dict, AbstractVector}}","page":"References","title":"TensorInference.log_probability","text":"log_probability(\n    tn::TensorNetworkModel,\n    config::Union{Dict, AbstractVector}\n) -> Real\n\n\nEvaluate the log probability of config.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.marginals-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.marginals","text":"marginals(\n    tn::TensorNetworkModel;\n    usecuda,\n    rescale\n) -> Vector\n\n\nReturns the marginal probability distribution of variables. One can use get_vars(tn) to get the full list of variables in this tensor network.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.maximum_logp-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.maximum_logp","text":"maximum_logp(\n    tn::TensorNetworkModel;\n    usecuda\n) -> AbstractArray{<:Real}\n\n\nReturns an output array containing largest log-probabilities.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.most_probable_config-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.most_probable_config","text":"most_probable_config(\n    tn::TensorNetworkModel;\n    usecuda\n) -> Tuple{Real, Vector}\n\n\nReturns the largest log-probability and the most probable configuration.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.probability-Tuple{TensorNetworkModel}","page":"References","title":"TensorInference.probability","text":"probability(\n    tn::TensorNetworkModel;\n    usecuda,\n    rescale\n) -> AbstractArray\n\n\nContract the tensor network and return a probability array with its rank specified in the contraction code tn.code. The returned array may not be l1-normalized even if the total probability is l1-normalized, because the evidence tn.fixedvertices may not be empty.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.read_evidence_file-Tuple{AbstractString}","page":"References","title":"TensorInference.read_evidence_file","text":"read_evidence_file(\n    evidence_filepath::AbstractString\n) -> Tuple{Vector{Int64}, Vector{Int64}}\n\n\nReturn the observed variables and values in evidence_filepath. If the passed file path is an empty string, return empty vectors.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.read_instance-Tuple{AbstractString}","page":"References","title":"TensorInference.read_instance","text":"read_instance(\n    model_filepath::AbstractString;\n    evidence_filepath,\n    query_filepath,\n    solution_filepath,\n    eltype\n) -> UAIInstance\n\n\nRead a UAI problem instance from a file.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.read_model_file-Tuple{Any}","page":"References","title":"TensorInference.read_model_file","text":"read_model_file(\n    model_filepath;\n    factor_eltype\n) -> Tuple{Int64, Vector{Int64}, Int64, Any}\n\n\nParse the problem instance found in model_filepath defined in the UAI model format.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.read_td_file-Tuple{AbstractString}","page":"References","title":"TensorInference.read_td_file","text":"read_td_file(\n    td_filepath::AbstractString\n) -> Tuple{Int64, Int64, Int64, Vector{Vector{Int64}}, Vector{Vector{Int64}}}\n\n\nParse a tree decomposition instance described the PACE format.\n\nThe PACE file format is defined in: https://pacechallenge.org/2017/treewidth/\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.sample-Tuple{TensorNetworkModel, Int64}","page":"References","title":"TensorInference.sample","text":"sample(\n    tn::TensorNetworkModel,\n    n::Int64;\n    usecuda\n) -> Matrix{Int64}\n\n\nGenerate samples from a tensor network based probabilistic model. Returns a vector of vector, each element being a configurations defined on get_vars(tn).\n\nArguments\n\ntn is the tensor network model.\nn is the number of samples to be returned.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.set_evidence!-Tuple{UAIInstance, Vararg{Pair{Int64}}}","page":"References","title":"TensorInference.set_evidence!","text":"set_evidence!(\n    uai::UAIInstance,\n    pairs::Pair{Int64}...\n) -> UAIInstance\n\n\nSet the evidence of an UAI instance.\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.MMAPModel","page":"References","title":"TensorInference.MMAPModel","text":"struct MMAPModel{LT, AT<:AbstractArray}\n\nComputing the most likely assignment to the query variables,  Xₘ ⊆ X after marginalizing out the remaining variables Xₛ = X \\ Xₘ.\n\nrm MMAP(X_iE=e) = arg max_X_M sum_X_S prod_F f(x_M x_S e)\n\nFields\n\nvars is the query variables in the tensor network.\ncode is the tropical tensor network contraction pattern.\ntensors is the tensors fed into the tensor network.\nclusters is the clusters, each element of this cluster is a TensorNetworkModel instance for marginalizing certain variables.\nfixedvertices is a dictionary to specifiy degree of freedoms fixed to certain values, which should not have overlap with the query variables.\n\n\n\n\n\n","category":"type"},{"location":"ref/#TensorInference.MMAPModel-Tuple{UAIInstance}","page":"References","title":"TensorInference.MMAPModel","text":"MMAPModel(\n    instance::UAIInstance;\n    queryvars,\n    openvertices,\n    optimizer,\n    simplifier\n)\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.MMAPModel-Union{Tuple{LT}, Tuple{T}, Tuple{AbstractVector{LT}, AbstractVector{Int64}, Vector{<:TensorInference.Factor{T}}}} where {T, LT}","page":"References","title":"TensorInference.MMAPModel","text":"MMAPModel(\n    vars::AbstractArray{LT, 1},\n    cards::AbstractVector{Int64},\n    factors::Array{<:TensorInference.Factor{T}, 1};\n    queryvars,\n    openvertices,\n    fixedvertices,\n    optimizer,\n    simplifier,\n    marginalize_optimizer,\n    marginalize_simplifier\n)\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.RescaledArray","page":"References","title":"TensorInference.RescaledArray","text":"struct RescaledArray{T, N, AT<:AbstractArray{T, N}} <: AbstractArray{T, N}\n\nRescaledArray(α, T) -> RescaledArray\n\nAn array data type with a log-prefactor, and a l∞-normalized storage, i.e. the maximum element in a tensor is 1. This tensor type can avoid the potential underflow/overflow of numbers in a tensor network. The constructor RescaledArray(α, T) creates a rescaled array that equal to exp(α) * T.\n\n\n\n\n\n","category":"type"},{"location":"ref/#TensorInference.TensorNetworkModel","page":"References","title":"TensorInference.TensorNetworkModel","text":"struct TensorNetworkModel{LT, ET, MT<:AbstractArray}\n\nProbabilistic modeling with a tensor network.\n\nFields\n\nvars is the degree of freedoms in the tensor network.\ncode is the tensor network contraction pattern.\ntensors is the tensors fed into the tensor network.\nfixedvertices is a dictionary to specifiy degree of freedoms fixed to certain values.\n\n\n\n\n\n","category":"type"},{"location":"ref/#TensorInference.TensorNetworkModel-Tuple{UAIInstance}","page":"References","title":"TensorInference.TensorNetworkModel","text":"TensorNetworkModel(\n    instance::UAIInstance;\n    openvertices,\n    optimizer,\n    simplifier\n) -> TensorNetworkModel{Int64}\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.TensorNetworkModel-Union{Tuple{LT}, Tuple{AbstractVector{LT}, OMEinsum.EinCode, Vector{<:AbstractArray}}} where LT","page":"References","title":"TensorInference.TensorNetworkModel","text":"TensorNetworkModel(\n    vars::AbstractArray{LT, 1},\n    rawcode::OMEinsum.EinCode,\n    tensors::Vector{<:AbstractArray};\n    fixedvertices,\n    optimizer,\n    simplifier\n) -> TensorNetworkModel\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.TensorNetworkModel-Union{Tuple{LT}, Tuple{T}, Tuple{AbstractVector{LT}, AbstractVector{Int64}, Vector{<:TensorInference.Factor{T}}}} where {T, LT}","page":"References","title":"TensorInference.TensorNetworkModel","text":"TensorNetworkModel(\n    vars::AbstractArray{LT, 1},\n    cards::AbstractVector{Int64},\n    factors::Array{<:TensorInference.Factor{T}, 1};\n    openvertices,\n    fixedvertices,\n    optimizer,\n    simplifier\n) -> TensorNetworkModel\n\n\n\n\n\n\n","category":"method"},{"location":"ref/#TensorInference.UAIInstance","page":"References","title":"TensorInference.UAIInstance","text":"struct UAIInstance{ET, FT<:(TensorInference.Factor{ET})}\n\nFields\n\nnvars is the number of variables,\nnclique is the number of cliques,\ncards is a vector of cardinalities for variables,\nfactors is a vector of factors,\nobsvars is a vector of observed variables,\nobsvals is a vector of observed values,\nqueryvars is a vector of query variables,\nreference_solution is a vector with the reference solution.\n\n\n\n\n\n","category":"type"},{"location":"ref/#Tensor-Network","page":"References","title":"Tensor Network","text":"","category":"section"},{"location":"ref/","page":"References","title":"References","text":"contraction_complexity\nGreedyMethod\nTreeSA\nSABipartite\nKaHyParBipartite\nMergeVectors\nMergeGreedy","category":"page"},{"location":"ref/#OMEinsumContractionOrders.contraction_complexity","page":"References","title":"OMEinsumContractionOrders.contraction_complexity","text":"contraction_complexity(tensor_network)\n\nReturns the contraction complexity of a tensor newtork model.\n\n\n\n\n\ncontraction_complexity(eincode, size_dict) -> ContractionComplexity\n\nReturns the time, space and read-write complexity of the einsum contraction. The returned object contains 3 fields:\n\ntime complexity tc defined as log2(number of element-wise multiplications).\nspace complexity sc defined as log2(size of the maximum intermediate tensor).\nread-write complexity rwc defined as log2(the number of read-write operations).\n\n\n\n\n\n","category":"function"},{"location":"ref/#OMEinsumContractionOrders.GreedyMethod","page":"References","title":"OMEinsumContractionOrders.GreedyMethod","text":"GreedyMethod{MT}\nGreedyMethod(; method=MinSpaceOut(), nrepeat=10)\n\nThe fast but poor greedy optimizer. Input arguments are\n\nmethod is MinSpaceDiff() or MinSpaceOut.\nMinSpaceOut choose one of the contraction that produces a minimum output tensor size,\nMinSpaceDiff choose one of the contraction that decrease the space most.\nnrepeat is the number of repeatition, returns the best contraction order.\n\n\n\n\n\n","category":"type"},{"location":"ref/#OMEinsumContractionOrders.TreeSA","page":"References","title":"OMEinsumContractionOrders.TreeSA","text":"TreeSA{RT,IT,GM}\nTreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,\n    sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))\n\nOptimize the einsum contraction pattern using the simulated annealing on tensor expression tree.\n\nsc_target is the target space complexity,\nntrials, βs and niters are annealing parameters, doing ntrials indepedent annealings, each has inverse tempteratures specified by βs, in each temperature, do niters updates of the tree.\nsc_weight is the relative importance factor of space complexity in the loss compared with the time complexity.\nrw_weight is the relative importance factor of memory read and write in the loss compared with the time complexity.\ninitializer specifies how to determine the initial configuration, it can be :greedy or :random. If it is using :greedy method to generate the initial configuration, it also uses two extra arguments greedy_method and greedy_nrepeat.\nnslices is the number of sliced legs, default is 0.\nfixed_slices is a vector of sliced legs, default is [].\n\nReferences\n\nRecursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits\n\n\n\n\n\n","category":"type"},{"location":"ref/#OMEinsumContractionOrders.SABipartite","page":"References","title":"OMEinsumContractionOrders.SABipartite","text":"SABipartite{RT,BT}\nSABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000\n    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)\n\nOptimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nsize_dict, a dictionary that specifies leg dimensions,\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nmax_group_size is the maximum size that allowed to used greedy search,\nβs is a list of inverse temperature 1/T,\nniters is the number of iteration in each temperature,\nntrials is the number of repetition (with different random seeds),\ngreedy_config configures the greedy method,\ninitializer, the partition configuration initializer, one can choose :random or :greedy (slow but better).\n\nReferences\n\nHyper-optimized tensor network contraction\n\n\n\n\n\n","category":"type"},{"location":"ref/#OMEinsumContractionOrders.KaHyParBipartite","page":"References","title":"OMEinsumContractionOrders.KaHyParBipartite","text":"KaHyParBipartite{RT,IT,GM}\nKaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),\n    max_group_size=40, greedy_config=GreedyMethod())\n\nOptimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nimbalances is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,\nmax_group_size is the maximum size that allowed to used greedy search,\ngreedy_config is a greedy optimizer.\n\nReferences\n\nHyper-optimized tensor network contraction\nSimulating the Sycamore quantum supremacy circuits\n\n\n\n\n\n","category":"type"},{"location":"ref/#OMEinsumContractionOrders.MergeVectors","page":"References","title":"OMEinsumContractionOrders.MergeVectors","text":"MergeVectors <: CodeSimplifier\nMergeVectors()\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.\n\n\n\n\n\n","category":"type"},{"location":"ref/#OMEinsumContractionOrders.MergeGreedy","page":"References","title":"OMEinsumContractionOrders.MergeGreedy","text":"MergeGreedy <: CodeSimplifier\nMergeGreedy(; threshhold=-1e-12)\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the threshhold).\n\n\n\n\n\n","category":"type"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = TensorInference","category":"page"},{"location":"#TensorInference","page":"Home","title":"TensorInference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TensorInference.","category":"page"}]
}
