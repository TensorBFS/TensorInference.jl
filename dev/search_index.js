var documenterSearchIndex = {"docs":
[{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"EditURL = \"https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/generated/asia/main.jl\"","category":"page"},{"location":"generated/asia/main/#The-ASIA-network","page":"Asia network","title":"The ASIA network","text":"","category":"section"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"The graph below corresponds to the ASIA network, a simple Bayesian model used extensively in educational settings. It was introduced by Lauritzen in 1988 [lauritzen1988local].","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"┌───┐           ┌───┐\n│ A │         ┌─┤ S ├─┐\n└─┬─┘         │ └───┘ │\n  │           │       │\n  ▼           ▼       ▼\n┌───┐       ┌───┐   ┌───┐\n│ T │       │ L │   │ B │\n└─┬─┘       └─┬─┘   └─┬─┘\n  │   ┌───┐   │       │\n  └──►│ E │◄──┘       │\n      └─┬─┘           │\n┌───┐   │   ┌───┐     │\n│ X │◄──┴──►│ D │◄────┘\n└───┘       └───┘","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"The table below explains the meanings of each random variable used in the ASIA network model.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Random variable Meaning\nA Recent trip to Asia\nT Patient has tuberculosis\nS Patient is a smoker\nL Patient has lung cancer\nB Patient has bronchitis\nE Patient hast T and/or L\nX Chest X-Ray is positive\nD Patient has dyspnoea","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"We now demonstrate how to use the TensorInference.jl package for conducting a variety of inference tasks on the Asia network.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Import the TensorInference package, which provides the functionality needed for working with tensor networks and probabilistic graphical models.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"using TensorInference","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Load the ASIA network model from the asia.uai file located in the examples directory. See Model file format (.uai) for a description of the format of this file.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"model = read_model_file(pkgdir(TensorInference, \"examples\", \"asia\", \"asia.uai\"))","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"UAIModel(nvars = 8, nclique = 8)\n variables :\n factors : \n  Factor(1), size = (2,)\n  Factor(1, 2), size = (2, 2)\n  Factor(3), size = (2,)\n  Factor(3, 4), size = (2, 2)\n  Factor(3, 5), size = (2, 2)\n  Factor(2, 4, 6), size = (2, 2, 2)\n  Factor(6, 7), size = (2, 2)\n  Factor(5, 6, 8), size = (2, 2, 2)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Create a tensor network representation of the loaded model.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"tn = TensorNetworkModel(model)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"TensorNetworkModel{Int64, OMEinsum.DynamicNestedEinsum{Int64}, Array{Float64}}\nvariables: 1, 2, 3, 4, 5, 6, 7, 8\ncontraction time = 2^6.044, space = 2^2.0, read-write = 2^7.098","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Calculate the log_10 partition function","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"probability(tn) |> first |> log10","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"0.0","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Calculate the marginal probabilities of each random variable in the model.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"marginals(tn)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8-element Vector{Vector{Float64}}:\n [0.01, 0.99]\n [0.0104, 0.9895999999999999]\n [0.5000000000000001, 0.5]\n [0.055000000000000014, 0.9450000000000001]\n [0.44999999999999996, 0.5499999999999999]\n [0.06482800000000002, 0.9351720000000001]\n [0.11029004000000002, 0.88970996]\n [0.43597060000000004, 0.5640294]","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Retrieve the variables associated with the tensor network model.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"get_vars(tn)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Set an evidence: Assume that the \"X-ray\" result (variable 7) is positive. Since setting an evidence may affect the contraction order of the tensor network, recompute it.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"tn = TensorNetworkModel(model, evidence = Dict(7 => 0))","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"TensorNetworkModel{Int64, OMEinsum.DynamicNestedEinsum{Int64}, Array{Float64}}\nvariables: 1, 2, 3, 4, 5, 6, 7 (evidence → 0), 8\ncontraction time = 2^6.0, space = 2^2.0, read-write = 2^7.066","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Calculate the maximum log-probability among all configurations.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"maximum_logp(tn)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"0-dimensional Array{Float64, 0}:\n-3.65222179200233","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Generate 10 samples from the probability distribution represented by the model.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"sample(tn, 10)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"8×10 Matrix{Int64}:\n 1  1  1  1  1  1  1  1  1  1\n 1  1  0  1  1  1  0  1  1  1\n 0  0  1  0  0  0  0  1  0  0\n 0  0  1  0  0  0  1  1  0  0\n 0  0  0  0  0  1  0  1  0  0\n 0  0  0  0  0  0  0  1  0  0\n 0  0  0  0  0  0  0  0  0  0\n 0  0  0  0  0  0  0  1  0  0","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Retrieve both the maximum log-probability and the most probable configuration. In this configuration, the most likely outcomes are that the patient smokes (variable 3) and has lung cancer (variable 4).","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"logp, cfg = most_probable_config(tn)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-3.65222179200233, [1, 1, 0, 0, 0, 0, 0, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Compute the most probable values of certain variables (e.g., 4 and 7) while marginalizing over others. This is known as Maximum a Posteriori (MAP) estimation.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"mmap = MMAPModel(model, evidence=Dict(7=>0), queryvars=[4,7])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"MMAPModel{Int64, Array{Float64}}\nvariables: 4, 7 (evidence → 0)\nquery variables: [[1, 2, 6, 5, 3, 8]]\ncontraction time = 2^6.0, space = 2^2.0, read-write = 2^7.0","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Get the most probable configurations for variables 4 and 7.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"most_probable_config(mmap)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-2.8754627318176693, [1, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"Compute the total log-probability of having lung cancer. The results suggest that the probability is roughly half.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"log_probability(mmap, [1, 0]), log_probability(mmap, [0, 0])","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"(-2.8754627318176693, -2.9206248010671856)","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"[lauritzen1988local]: Steffen L Lauritzen and David J Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society: Series B (Methodological), 50(2):157–194, 1988.","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"","category":"page"},{"location":"generated/asia/main/","page":"Asia network","title":"Asia network","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples-overview/#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"examples-overview/","page":"Overview","title":"Overview","text":"Pages = [\n  \"generated/asia/main.md\",\n]\nDepth = 1","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"EditURL = \"https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/generated/performance.jl\"","category":"page"},{"location":"generated/performance/#Performance-Tips","page":"Performance tips","title":"Performance Tips","text":"","category":"section"},{"location":"generated/performance/#Optimize-contraction-orders","page":"Performance tips","title":"Optimize contraction orders","text":"","category":"section"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Let us use a problem instance from the \"Promedus\" dataset of the UAI 2014 competition as an example.","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"using TensorInference\nproblem = problem_from_artifact(\"uai2014\", \"MAR\", \"Promedus\", 11)\nmodel, evidence = read_model(problem), read_evidence(problem);","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Next, we select the tensor network contraction order optimizer.","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"optimizer = TreeSA(ntrials = 1, niters = 5, βs = 0.1:0.3:100)","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"TreeSA{Int64, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, GreedyMethod{OMEinsumContractionOrders.MinSpaceOut}, Any}(20, 0.1:0.3:100.0, 1, 5, 1.0, 0.2, :greedy, 0, Any[], GreedyMethod{OMEinsumContractionOrders.MinSpaceOut}(OMEinsumContractionOrders.MinSpaceOut(), 1))","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Here, we choose the local search based TreeSA algorithm, which often finds the smallest time/space complexity and supports slicing. One can type ?TreeSA in a Julia REPL for more information about how to configure the hyper-parameters of the TreeSA method, while the detailed algorithm explanation is in arXiv: 2108.05665. Alternative tensor network contraction order optimizers include","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"GreedyMethod (default, fastest in searching speed but worst in contraction complexity)\nKaHyParBipartite\nSABipartite","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"tn = TensorNetworkModel(model; optimizer, evidence);","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"The returned object tn contains a field code that specifies the tensor network with optimized contraction order. To check the contraction complexity, please type","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"contraction_complexity(tn)","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Time complexity (number of element-wise multiplications) = 2^21.71179130602278\nSpace complexity (number of elements in the largest intermediate tensor) = 2^16.0\nRead-write complexity (number of element-wise read and write) = 2^19.152534903357036","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"The returned object contains log2 values of the number of multiplications, the number elements in the largest tensor during contraction and the number of read-write operations to tensor elements.","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"probability(tn)","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"exp(-19.322038772705987) * fill(1.0)","category":"page"},{"location":"generated/performance/#Using-the-slicing-technique-to-reduce-the-memory-cost","page":"Performance tips","title":"Using the slicing technique to reduce the memory cost","text":"","category":"section"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"For large scale applications, it is also possible to slice over certain degrees of freedom to reduce the space complexity, i.e. loop and accumulate over certain degrees of freedom so that one can have a smaller tensor network inside the loop due to the removal of these degrees of freedom. In the TreeSA optimizer, one can set nslices to a value larger than zero to turn on this feature. As a comparison we slice over 5 degrees of freedom, which can reduce the space complexity by at most 5. In this application, the slicing achieves the largest possible space complexity reduction 5, while the time and read-write complexity are only increased by less than 1, i.e. the peak memory usage is reduced by a factor 32, while the (theoretical) computing time is increased by at a factor  2.","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"optimizer = TreeSA(ntrials = 1, niters = 5, βs = 0.1:0.3:100, nslices=5)\ntn = TensorNetworkModel(model; optimizer, evidence);\ncontraction_complexity(tn)","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Time complexity (number of element-wise multiplications) = 2^21.802516365121217\nSpace complexity (number of elements in the largest intermediate tensor) = 2^10.0\nRead-write complexity (number of element-wise read and write) = 2^20.597848879637915","category":"page"},{"location":"generated/performance/#Faster-Tropical-tensor-contraction-to-speed-up-MAP-and-MMAP","page":"Performance tips","title":"Faster Tropical tensor contraction to speed up MAP and MMAP","text":"","category":"section"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"One can enjoy the BLAS level speed provided by TropicalGEMM by importing the package with","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"using TropicalGEMM","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"The benchmark in the TropicalGEMM repo shows this performance is close to the theoretical optimal value. Its implementation on GPU is under development in Github repo CuTropicalGEMM.jl as a part of Open Source Promotion Plan summer program.","category":"page"},{"location":"generated/performance/#Working-with-GPUs","page":"Performance tips","title":"Working with GPUs","text":"","category":"section"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"To upload the computation to GPU, you just add using CUDA before calling the solve function, and set the keyword argument usecuda to true.","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"julia> using CUDA\n[ Info: OMEinsum loaded the CUDA module successfully\n\njulia> marginals(tn; usecuda = true);","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Functions support usecuda keyword argument includes","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"probability\nlog_probability\nmarginals\nmost_probable_config","category":"page"},{"location":"generated/performance/#Benchmarks","page":"Performance tips","title":"Benchmarks","text":"","category":"section"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"Please check our paper (link to be added).","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"","category":"page"},{"location":"generated/performance/","page":"Performance tips","title":"Performance tips","text":"This page was generated using Literate.jl.","category":"page"},{"location":"uai-file-formats/#UAI-file-formats","page":"UAI file formats","title":"UAI file formats","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The UAI Format consists of four potential parts (each associated with a file):","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Model file format (.uai).\nEvidence file format (.evid).\nQuery file format (.query).\nResults file format (.MAR, .MAP, .MMAP .PR).","category":"page"},{"location":"uai-file-formats/#Model-file-format-(.uai)","page":"UAI file formats","title":"Model file format (.uai)","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"We use the simple text file format specified below to describe problem instances (Markov networks). The format is a generalization of the Ergo file format initially developed by Noetic Systems Inc. for their Ergo software. We use the .uai suffix for the evaluation benchmark network files.","category":"page"},{"location":"uai-file-formats/#Structure","page":"UAI file formats","title":"Structure","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"A file in the UAI format consists of the following two parts, in that order:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"<Preamble>\n\n<Function tables>","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The contents of each section (denoted <...> above) are described in the following:","category":"page"},{"location":"uai-file-formats/#Preamble","page":"UAI file formats","title":"Preamble","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Our description of the format will follow a simple Markov network with three variables and two functions. A sample preamble for such a network is:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"MARKOV\n3\n2 2 3\n2\n2 0 1\n2 1 2","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The preamble starts with one line denoting the type of network. Generally, this can be either BAYES (if the network is a Bayesian network) or MARKOV (in case of a Markov network). However, note that this year all networks will be given in a Markov networks (i.e. Bayesian networks will be moralized).","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The second line contains the number of variables. The next line specifies the cardinalities of each variable, one at a time, separated by a whitespace (note that this implies an order on the variables which will be used throughout the file). The fourth line contains only one integer, denoting the number of cliques in the problem. Then, one clique per line, the scope of each clique is given as follows: The first integer in each line specifies the number of variables in the clique, followed by the actual indexes of the variables. The order of this list is not restricted. Note that the ordering of variables within a factor will follow the order provided here.","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Referring to the example above, the first line denotes the Markov network, the second line tells us the problem consists of three variables, let's refer to them as X, Y, and Z. Their cardinalities are 2, 2, and 3 respectively (from the third line). Line four specifies that there are 2 cliques. The first clique is X,Y, while the second clique is Y,Z. Note that variables are indexed starting with 0.","category":"page"},{"location":"uai-file-formats/#Function-tables","page":"UAI file formats","title":"Function tables","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"In this section each factor is specified by giving its full table (i.e, specifying value for each assignment). The order of the factor is identical to the one in which they were introduced in the preamble, the first variable have the role of the 'most significant' digit. For each factor table, first the number of entries is given (this should be equal to the product of the domain sizes of the variables in the scope). Then, one by one, separated by whitespace, the values for each assignment to the variables in the function's scope are enumerated. Tuples are implicitly assumed in ascending order, with the last variable in the scope as the 'least significant'. To illustrate, we continue with our Markov network example from above, let's assume the following conditional probability tables:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"X     P(X)\n0     0.436\n1     0.564\n\nX Y   P(Y,X)\n0 0   0.128\n0 1   0.872\n1 0   0.920\n1 1   0.080\n\nY Z   P(Z,Y)\n0 0   0.210\n0 1   0.333\n0 2   0.457\n1 0   0.811\n1 1   0.000\n1 2   0.189","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The corresponding function tables in the file would then look like this:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"2\n0.436 0.564\n\n4\n0.128 0.872\n0.920 0.080\n\n6\n0.210 0.333 0.457\n0.811 0.000 0.189","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"(Note that line breaks and empty lines are effectively just a whitespace, exactly like plain spaces \" \". They are used here to improve readability.)","category":"page"},{"location":"uai-file-formats/#Summary","page":"UAI file formats","title":"Summary","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"To sum up, a problem file consists of 2 sections: the preamble and the full the function tables, the names and the labels. For our Markov network example above, the full file will look like:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"MARKOV\n3\n2 2 3\n3\n1 0\n2 0 1\n2 1 2\n\n2\n0.436 0.564\n\n4\n0.128 0.872\n0.920 0.080\n\n6\n0.210 0.333 0.457\n0.811 0.000 0.189","category":"page"},{"location":"uai-file-formats/#Evidence-file-format-(.evid)","page":"UAI file formats","title":"Evidence file format (.evid)","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Evidence is specified in a separate file. This file has the same name as the original network file but with an added .evid suffix. For instance, problem.uai will have evidence in problem.uai.evid. The file starts with a line specifying the number of evidences samples. The evidence in each sample, will be written in a new line. Each line will begin with the number of observed variables in the sample, followed by pairs of variable and its observed value. The indexes correspond to the ones implied by the original problem file. If, for our above example, we want to provide a single sample where the variable Y   has been observed as having its first value and Z with its second value, the   file example.uai.evid would contain the following:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"1\n2 1 0 2 1","category":"page"},{"location":"uai-file-formats/#Query-file-format-(.query)","page":"UAI file formats","title":"Query file format (.query)","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Query variables for marginal MAP (MMAP) inference are specified in a separate file. This file has the same name as the original network file but with an added .query suffix. For instance with respect to the UAI model format, problem.uai will have evidence in problem.uai.query.","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The query file consists of a single line. The line will begin with the number of query variables, followed by the indexes of the query variables. The indexes correspond to the ones implied by the original problem file.","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"For our example Markov network given Model Format, if we wanted to use Y as the query variable the file example.uai.query would contain the following:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"1 1","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"As a second example, if variables with indices 0, 4, 8 and 17 are query variables, the query file would contain the following:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"4 0 4 8 17","category":"page"},{"location":"uai-file-formats/#Results-file-format-(.MAR,-.MAP,-.MMAP-.PR)","page":"UAI file formats","title":"Results file format (.MAR, .MAP, .MMAP .PR)","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The rest of the file will contain the solution for the task. The first line must contain one of the tasks (PR, MPE, MAR, MMAP, or MLC) solved.","category":"page"},{"location":"uai-file-formats/#Marginals,-MAR","page":"UAI file formats","title":"Marginals, MAR","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"A space separated line that includes:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The number of variables in the model.\nA list of marginal approximations of all the variables. For each variable its cardinality is first stated, then the probability of each state is stated. The order of the variables is the same as in the model, all data is space separated.\nFor example, a model with 3 variables, with cardinalities of 2, 2, 3 respectively. The solution might look like this:\n  3 2 0.1 0.9 2 0.3 0.7 3 0.2 0.2 0.6","category":"page"},{"location":"uai-file-formats/#Marginal-MAP,-MMAP","page":"UAI file formats","title":"Marginal MAP, MMAP","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"A space separated line that includes:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"The number of query variables.\nthe most probable instantiation, a list of variable value pairs for all bmQ variables.\nFor example, if the solution is an assignment of 0, 1 and 0 to three query variables indexed by 2 3 and 4 respectively, the solution will look as follows:\n  3 2 0 3 1 4 0","category":"page"},{"location":"uai-file-formats/#Partition-function,-PR","page":"UAI file formats","title":"Partition function, PR","text":"","category":"section"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"Line with the value of the log_10 of the partition function.","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"For example, an approximation log_10 Pr(bme) = -02008, which is known to be an upper bound may have a solution line:","category":"page"},{"location":"uai-file-formats/","page":"UAI file formats","title":"UAI file formats","text":"-0.2008","category":"page"},{"location":"api/internal/#Internal-API","page":"Internal","title":"Internal API","text":"","category":"section"},{"location":"api/internal/#Index","page":"Internal","title":"Index","text":"","category":"section"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Types","category":"page"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Pages = [\"internal.md\"]\nOrder = [:type]","category":"page"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Functions","category":"page"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Pages = [\"internal.md\"]\nOrder = [:function]","category":"page"},{"location":"api/internal/#internal_Types","page":"Internal","title":"Types","text":"","category":"section"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Modules = [TensorInference]\nOrder   = [:type]\nPublic = false","category":"page"},{"location":"api/internal/#TensorInference.Factor","page":"Internal","title":"TensorInference.Factor","text":"struct Factor{T, N}\n\nFields\n\nvars\nvals\n\nEncodes a discrete function over the set of variables vars that maps each instantiation of vars into a nonnegative number in vals.\n\n\n\n\n\n","category":"type"},{"location":"api/internal/#TensorInference.Samples","page":"Internal","title":"TensorInference.Samples","text":"struct Samples{L}\n\nFields\n\nsamples::Matrix{Int64}\nlabels::Vector\nsetmask::BitVector\n\nThe sampled configurations are stored in samples, which is a vector of vector. labels is a vector of variable names for labeling configurations. The setmask is an boolean indicator to denote whether the sampling process of a variable is complete.\n\n\n\n\n\n","category":"type"},{"location":"api/internal/#internal_Functions","page":"Internal","title":"Functions","text":"","category":"section"},{"location":"api/internal/","page":"Internal","title":"Internal","text":"Modules = [TensorInference]\nOrder   = [:function]\nPublic = false","category":"page"},{"location":"api/internal/#TensorInference.backward_sampling!-Tuple{Any, Tuple, Any, Any, TensorInference.Samples, Any}","page":"Internal","title":"TensorInference.backward_sampling!","text":"backward_sampling!(\n    ixs,\n    xs::Tuple,\n    iy,\n    y,\n    samples::TensorInference.Samples,\n    size_dict\n) -> TensorInference.Samples\n\n\nThe backward process for sampling configurations.\n\nixs and xs are labels and tensor data for input tensors,\niy and y are labels and tensor data for the output tensor,\nsamples is the samples generated for eliminated variables,\nsize_dict is a key-value map from tensor label to dimension size.\n\n\n\n\n\n","category":"method"},{"location":"api/internal/#TensorInference.backward_tropical-Tuple{Any, Tuple, Vararg{Any, 4}}","page":"Internal","title":"TensorInference.backward_tropical","text":"backward_tropical(\n    ixs,\n    xs::Tuple,\n    iy,\n    y,\n    ymask,\n    size_dict\n) -> Vector{Any}\n\n\nThe backward rule for tropical einsum.\n\nixs and xs are labels and tensor data for input tensors,\niy and y are labels and tensor data for the output tensor,\nymask is the boolean mask for gradients,\nsize_dict is a key-value map from tensor label to dimension size.\n\n\n\n\n\n","category":"method"},{"location":"api/internal/#TensorInference.parse_mar_solution_file-Tuple{Vector{String}}","page":"Internal","title":"TensorInference.parse_mar_solution_file","text":"parse_mar_solution_file(\n    rawlines::Vector{String};\n    factor_eltype\n) -> Vector{Vector{Float64}}\n\n\nParse the solution marginals of all variables from the UAI MAR solution file. The order of the variables is the same as in the model definition.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"method"},{"location":"api/internal/#TensorInference.read_query_file-Tuple{AbstractString}","page":"Internal","title":"TensorInference.read_query_file","text":"read_query_file(\n    query_filepath::AbstractString\n) -> Vector{Int64}\n\n\nReturn the query variables in query_filepath. If the passed file path is an empty string, return an empty vector.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"method"},{"location":"api/internal/#TensorInference.rescale_array-Union{Tuple{AbstractArray{T}}, Tuple{T}} where T","page":"Internal","title":"TensorInference.rescale_array","text":"rescale_array(tensor::AbstractArray{T}) -> RescaledArray\n\n\nReturns a rescaled array that equivalent to the input tensor.\n\n\n\n\n\n","category":"method"},{"location":"background/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"TensorInference implements efficient methods to perform Bayesian inference in probabilistic graphical models, such as Bayesian Networks or Markov random fields. This page introduces probabilistic graphical models, provides an example using a Bayesian network, and explains what probabilistic inference is, including the different tasks it can involve.","category":"page"},{"location":"background/#Probabilistic-graphical-models","page":"Background","title":"Probabilistic graphical models","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"A probabilistic graphical model (PGM) is a mathematical framework that uses graphs to compactly represent complex multivariate statistical distributions. They are used to reason in the presence of uncertainty. This reasoning process is known as probabilistic inference and will be defined and discussed in detail later on.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Bayesian networks and Markov random fields are popular types of PGMs. The following PGM is an example of a Bayesian network called the ASIA network. It was introduced by Lauritzen in 1988 [lauritzen1988local].","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"using TikzPictures\n\ntp = TikzPicture(\n  L\"\"\"\n    % The various elements are conveniently placed using a matrix:\n    \\matrix[row sep=0.5cm,column sep=0.5cm] {\n      % First line\n      \\node (a) [myvar] {$A$};  &\n                                &\n                                &\n      \\node (s) [myvar] {$S$};  &\n                               \\\\\n      % Second line\n      \\node (t) [myvar] {$T$};  &\n                                &\n      \\node (l) [myvar] {$L$};  &\n                                &\n      \\node (b) [myvar] {$B$}; \\\\\n      % Third line\n                                &\n      \\node (e) [myvar] {$E$};  &\n                                &\n                                &\n                               \\\\\n      % Forth line\n      \\node (x) [myvar] {$X$};  &\n                                &\n                                &\n      \\node (d) [myvar] {$D$};  &\n                               \\\\\n  };\n\n  \\draw [myarrow] (a) edge (t);\n  \\draw [myarrow] (s) edge (l);\n  \\draw [myarrow] (s) edge (b);\n  \\draw [myarrow] (t) edge (e);\n  \\draw [myarrow] (l) edge (e);\n  \\draw [myarrow] (e) edge (x);\n  \\draw [myarrow] (e) edge (d);\n  \\draw [myarrow] (b) edge (d);\n  \"\"\",\n  options=\"every node/.style={scale=1.5}\",\n  preamble=\"\\\\input{\" * joinpath(@__DIR__, \"assets\", \"preambles\", \"asia-network\") * \"}\",\n)\nsave(SVG(joinpath(@__DIR__, \"asia-bayesian-network\")), tp)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"(Image: )","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Random variable Meaning\nA Recent trip to Asia\nT Patient has tuberculosis\nS Patient is a smoker\nL Patient has lung cancer\nB Patient has bronchitis\nE Patient hast T and/or L\nX Chest X-Ray is positive\nD Patient has dyspnoea","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This network represents a simplified example from the realm of medical diagnosis, illustrating the probabilistic relationships between various random variables that correspond to potential diseases, symptoms, risk factors, and test results. It comprises a graph G = (bmVmathcalE) and a probability distribution P(bmV), where G is a directed acyclic graph, bmV represents the set of variables, and mathcalE is the set of edges connecting these variables. We assume all variables are discrete. Each variable V is quantified by a conditional probability distribution (CPD) P(V mid pa(V)), where pa(V) denotes the parent variables of V. Collectively, these conditional probability distributions, together with the graph G, induce a joint probability distribution over P(bmV), given by","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"P(bmV) = prod_VinbmV P(V mid pa(V))","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"A factor, denoted as phi_bmV, is defined over a set of variables bmV. It's a function that maps each instantiation bmV = bmv to a non-negative number. It's important to note that a probability distribution is a specific case of a factor. The product of two factors, phi_bmX and phi_bmY, is another factor, phi_bmZ, where bmZ = bmX cup bmY, and phi_bmZ(bmz) = phi_bmX(bmx)phi_bmY(bmy) for the instantiations bmx and bmy that align with the instantiation bmz. The marginalization of a factor phi_bmY into bmX subseteq bmY results in a new factor phi_bmX, where each phi_bmX(bmx) is calculated by summing the values of phi_bmY(bmy) for all bmy that are consistent with bmx. Importantly, factor marginalization and product operations form the fundamental basis for conducting probabilistic inference in PGMs.","category":"page"},{"location":"background/#The-inference-tasks","page":"Background","title":"The inference tasks","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Probabilistic inference is the process of determining the probability distribution of a set of unknown variables, given the values of known variables in a PGM. It encompasses several tasks that will be explained next.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Each task is performed with respect to a graphical model, denoted as G = bmV bmD bmphi, where:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"bmV =  V_1  V_2  dots  V_N  is the set of the model’s variables","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"bmD =  D_V_1  D_V_2  dots  D_V_N  is the set of discrete domains for each variable, and","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"bmphi =  phi_1  phi_2  dots  phi_N  is the set of factors that define the joint probability distribution of the model.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"The variable set bmV can be further partitioned into two subsets: the evidence variables bmE and the remaining variables bmV^prime = bmV setminus bmE. Furthermore, within the set bmV^prime, the subset bmQ denotes the query variables. These are the variables for which we aim to estimate or infer values.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"using TikzPictures\n\ntp = TikzPicture(\n  L\"\"\"\n    %\\draw[help lines] (0,0) grid (10,-7);\n\n    % mrv: the \"node distances\" refer to the distance between the edge of a shape\n    % to the edge of the other shape. That is why I use \"ie_aux\" and \"tasks_aux\"\n    % below: to have equal distances between nodes with respect to the center of\n    % the shapes.\n\n    % row 1\n    \\node[myroundbox] (rv) {Random Variables\\\\$\\bm{V}$};\n    \\node[right=of rv](aux1) {};\n    \\node[right=of aux1,myroundbox] (jd) {Joint Distribution\\\\$P(\\bm{V})$};\n    \\node[right=of jd](aux2) {};\n    \\node[right=of aux2,myroundbox] (e) {Evidence\\\\$\\bm{E=e}$};\n    \\node[right=of e](aux3) {};\n    \\node[right=of aux3,myroundbox] (qv) {Query Variables\\\\$\\bm{Q}$};\n    % row 2\n    \\node[below=of aux2,myrectbox] (ie) {Inference Engine};\n    \\node[below=of aux2] (ie_aux) {};\n    % row 3\n    \\node[below=of ie_aux] (tasks_aux) {};\n    \\node[left=of tasks_aux,myroundbox] (mar) {MAR};\n    \\node[left=of mar] (aux4) {};\n    \\node[left=of aux4,myroundbox] (pr) {PR};\n    \\node[right=of tasks_aux,myroundbox] (map) {MAP};\n    \\node[right=of map] (aux5) {};\n    \\node[right=of aux5,myroundbox] (mmap) {MMAP};\n    % row 0\n    \\node[above=of aux2,yshift=-12mm,text=gray] (in) {\\textbf{Input}};\n    % row 4\n    \\node[below=of tasks_aux,yshift=7mm,text=gray] (out) {\\textbf{Output}};\n\n    %% edges\n    \\draw[myarrow] (rv) -- (ie);\n    \\draw[myarrow] (jd) -- (ie);\n    \\draw[myarrow] (e)  -- (ie);\n    \\draw[myarrow] (qv) -- (ie);\n    \\draw[myarrow] (ie) -- (pr);\n    \\draw[myarrow] (ie) -- (mar);\n    \\draw[myarrow] (ie) -- (map);\n    \\draw[myarrow] (ie) -- (mmap);\n  \"\"\",\n  options=\"transform shape, scale=1.8\",\n  preamble=\"\\\\input{\" * joinpath(@__DIR__, \"assets\", \"preambles\", \"the-inference-tasks\") * \"}\",\n)\nsave(SVG(\"the-inference-tasks\"), tp)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"(Image: )","category":"page"},{"location":"background/#Probability-of-evidence-(PR)","page":"Background","title":"Probability of evidence (PR)","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Computing the partition function (ie. normalizing constant) or probability of evidence:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"PR(bmV^prime mid bmE=bme) = sum_V^prime in bmV^prime prod_phi in bmphi phi(V^primebme)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This task involves calculating the probability of the observed evidence, which can be useful for model comparison or anomaly detection. This involves summing the joint probability over all possible states of the unobserved variables in the model, given some observed variables. This is a fundamental task in Bayesian statistics and is often used as a stepping stone for other types of inference.","category":"page"},{"location":"background/#Marginal-inference-(MAR):","page":"Background","title":"Marginal inference (MAR):","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Computing the marginal probability distribution over all variables given evidence:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"MAR(V_i mid bmE=bme) = frac sum_V^primeprime in bmV^prime\nsetminus V_i prod_phi in bmphi phi(V^primeprimebme) \n    PR(bmV^prime mid bmE=bme) ","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This task involves computing the marginal probability of a subset of variables, integrating out the others. In other words, it computes the probability distribution of some variables of interest regardless of the states of all other variables. This is useful when we're interested in the probabilities of some specific variables in the model, but not the entire model.","category":"page"},{"location":"background/#Maximum-a-Posteriori-Probability-estimation-(MAP)","page":"Background","title":"Maximum a Posteriori Probability estimation (MAP)","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Computing the most likely assignment to all variables given evidence:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"MAP(V_i mid bmE=bme) = arg max_V^prime in bmV^prime\nprod_phi in bmphi phi(V^primebme)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"In the MAP task, given some observed variables, the goal is to find the most probable assignment of values to some subset of the unobserved variables. It provides the states of variables that maximize the posterior probability given some observed evidence. This is often used when we want the most likely explanation or prediction according to the model.","category":"page"},{"location":"background/#Marginal-Maximum-a-Posteriori-(MMAP)","page":"Background","title":"Marginal Maximum a Posteriori (MMAP)","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"Computing the most likely assignment to the query variables, bmQ subset bmV^prime after marginalizing out the remaining variables bmZ = bmV^prime setminus bmQ, also known as hidden or latent variables:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"MMAP(V_i mid bmE=e) = arg max_Q in bmQ sum_Z in bmZ\nprod_phi in bmphi phi(Q Z e)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"This task is essentially a combination of the MAR and MAP tasks. The MMAP task involves finding the most probable assignment (the MAP estimate) for a subset of the variables, while marginalizing over (summing out) the remaining variables. This task is useful when we want to know the most likely state of some variables, but there's some uncertainty over others that we need to average out.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[lauritzen1988local]: Steffen L Lauritzen and David J Spiegelhalter. Local computations with probabilities on graphical structures and their application to expert systems. Journal of the Royal Statistical Society: Series B (Methodological), 50(2):157–194, 1988.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = TensorInference","category":"page"},{"location":"#TensorInference.jl","page":"Home","title":"TensorInference.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TensorInference is a standalone solver written in Julia, that harnesses tensor-based technology to implement state-of-the-art algorithms for probabilistic inference in graphical models. ","category":"page"},{"location":"#Package-features","page":"Home","title":"Package features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Solutions to the most common probabilistic inference tasks, including:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Probability of evidence (PR): Calculates the total probability of the observed evidence across all possible states of the unobserved variables.\nMarginal inference (MAR): Computes the probability distribution of a subset of variables, ignoring the states of all other variables.\nMaximum a Posteriori Probability estimation (MAP): Finds the most probable state of a subset of unobserved variables given some observed evidence.\nMarginal Maximum a Posteriori (MMAP): Finds the most probable state of a subset of variables, averaging out the uncertainty over the remaining ones.","category":"page"},{"location":"#Outline","page":"Home","title":"Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n  \"background.md\",\n  \"examples-overview.md\",\n  \"uai-file-formats.md\",\n  \"performance.md\",\n  \"api/public.md\",\n  \"api/internal.md\",\n]\nDepth = 1","category":"page"},{"location":"api/public/#Public-API","page":"Public","title":"Public API","text":"","category":"section"},{"location":"api/public/#Index","page":"Public","title":"Index","text":"","category":"section"},{"location":"api/public/","page":"Public","title":"Public","text":"Modules","category":"page"},{"location":"api/public/","page":"Public","title":"Public","text":"Pages = [\"public.md\"]\nOrder   = [:module]","category":"page"},{"location":"api/public/","page":"Public","title":"Public","text":"Types","category":"page"},{"location":"api/public/","page":"Public","title":"Public","text":"Pages = [\"public.md\"]\nOrder   = [:type]","category":"page"},{"location":"api/public/","page":"Public","title":"Public","text":"Functions","category":"page"},{"location":"api/public/","page":"Public","title":"Public","text":"Pages = [\"public.md\"]\nOrder   = [:function]","category":"page"},{"location":"api/public/#Modules","page":"Public","title":"Modules","text":"","category":"section"},{"location":"api/public/","page":"Public","title":"Public","text":"TensorInference","category":"page"},{"location":"api/public/#TensorInference","page":"Public","title":"TensorInference","text":"Main module for TensorInference.jl – A toolbox for probabilistic inference using contraction of tensor networks.\n\nExports\n\nArtifactProblemSpec\nGreedyMethod\nKaHyParBipartite\nMMAPModel\nMergeGreedy\nMergeVectors\nRescaledArray\nSABipartite\nTensorNetworkModel\nTreeSA\nUAIModel\ncontraction_complexity\ndataset_from_artifact\nget_cards\nget_vars\nlog_probability\nmarginals\nmaximum_logp\nmost_probable_config\nprobability\nproblem_from_artifact\nread_evidence\nread_evidence_file\nread_model\nread_model_file\nread_queryvars\nread_solution\nread_td_file\nsample\n\n\n\n\n\n","category":"module"},{"location":"api/public/#Types","page":"Public","title":"Types","text":"","category":"section"},{"location":"api/public/","page":"Public","title":"Public","text":"GreedyMethod\nKaHyParBipartite\nMergeGreedy\nMergeVectors\nSABipartite\nTreeSA\nMMAPModel\nRescaledArray\nTensorNetworkModel\nArtifactProblemSpec\nUAIModel","category":"page"},{"location":"api/public/#OMEinsumContractionOrders.GreedyMethod","page":"Public","title":"OMEinsumContractionOrders.GreedyMethod","text":"GreedyMethod{MT}\nGreedyMethod(; method=MinSpaceOut(), nrepeat=10)\n\nThe fast but poor greedy optimizer. Input arguments are\n\nmethod is MinSpaceDiff() or MinSpaceOut.\nMinSpaceOut choose one of the contraction that produces a minimum output tensor size,\nMinSpaceDiff choose one of the contraction that decrease the space most.\nnrepeat is the number of repeatition, returns the best contraction order.\n\n\n\n\n\n","category":"type"},{"location":"api/public/#OMEinsumContractionOrders.KaHyParBipartite","page":"Public","title":"OMEinsumContractionOrders.KaHyParBipartite","text":"KaHyParBipartite{RT,IT,GM}\nKaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),\n    max_group_size=40, greedy_config=GreedyMethod())\n\nOptimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nimbalances is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,\nmax_group_size is the maximum size that allowed to used greedy search,\ngreedy_config is a greedy optimizer.\n\nReferences\n\nHyper-optimized tensor network contraction\nSimulating the Sycamore quantum supremacy circuits\n\n\n\n\n\n","category":"type"},{"location":"api/public/#OMEinsumContractionOrders.MergeGreedy","page":"Public","title":"OMEinsumContractionOrders.MergeGreedy","text":"MergeGreedy <: CodeSimplifier\nMergeGreedy(; threshhold=-1e-12)\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the threshhold).\n\n\n\n\n\n","category":"type"},{"location":"api/public/#OMEinsumContractionOrders.MergeVectors","page":"Public","title":"OMEinsumContractionOrders.MergeVectors","text":"MergeVectors <: CodeSimplifier\nMergeVectors()\n\nContraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.\n\n\n\n\n\n","category":"type"},{"location":"api/public/#OMEinsumContractionOrders.SABipartite","page":"Public","title":"OMEinsumContractionOrders.SABipartite","text":"SABipartite{RT,BT}\nSABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000\n    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)\n\nOptimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by max_group_size and maximum space complexity specified by sc_target, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are\n\nsize_dict, a dictionary that specifies leg dimensions,\nsc_target is the target space complexity, defined as log2(number of elements in the largest tensor),\nmax_group_size is the maximum size that allowed to used greedy search,\nβs is a list of inverse temperature 1/T,\nniters is the number of iteration in each temperature,\nntrials is the number of repetition (with different random seeds),\ngreedy_config configures the greedy method,\ninitializer, the partition configuration initializer, one can choose :random or :greedy (slow but better).\n\nReferences\n\nHyper-optimized tensor network contraction\n\n\n\n\n\n","category":"type"},{"location":"api/public/#OMEinsumContractionOrders.TreeSA","page":"Public","title":"OMEinsumContractionOrders.TreeSA","text":"TreeSA{RT,IT,GM}\nTreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,\n    sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))\n\nOptimize the einsum contraction pattern using the simulated annealing on tensor expression tree.\n\nsc_target is the target space complexity,\nntrials, βs and niters are annealing parameters, doing ntrials indepedent annealings, each has inverse tempteratures specified by βs, in each temperature, do niters updates of the tree.\nsc_weight is the relative importance factor of space complexity in the loss compared with the time complexity.\nrw_weight is the relative importance factor of memory read and write in the loss compared with the time complexity.\ninitializer specifies how to determine the initial configuration, it can be :greedy or :random. If it is using :greedy method to generate the initial configuration, it also uses two extra arguments greedy_method and greedy_nrepeat.\nnslices is the number of sliced legs, default is 0.\nfixed_slices is a vector of sliced legs, default is [].\n\nReferences\n\nRecursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits\n\n\n\n\n\n","category":"type"},{"location":"api/public/#TensorInference.MMAPModel","page":"Public","title":"TensorInference.MMAPModel","text":"struct MMAPModel{LT, AT<:AbstractArray}\n\nComputing the most likely assignment to the query variables,  Xₘ ⊆ X after marginalizing out the remaining variables Xₛ = X \\ Xₘ.\n\nrm MMAP(X_iE=e) = arg max_X_M sum_X_S prod_F f(x_M x_S e)\n\nFields\n\nvars is the query variables in the tensor network.\ncode is the tropical tensor network contraction pattern.\ntensors is the tensors fed into the tensor network.\nclusters is the clusters, each element of this cluster is a TensorNetworkModel instance for marginalizing certain variables.\nevidence is a dictionary to specifiy degree of freedoms fixed to certain values, which should not have overlap with the query variables.\n\n\n\n\n\n","category":"type"},{"location":"api/public/#TensorInference.RescaledArray","page":"Public","title":"TensorInference.RescaledArray","text":"struct RescaledArray{T, N, AT<:AbstractArray{T, N}} <: AbstractArray{T, N}\n\nRescaledArray(α, T) -> RescaledArray\n\nAn array data type with a log-prefactor, and a l∞-normalized storage, i.e. the maximum element in a tensor is 1. This tensor type can avoid the potential underflow/overflow of numbers in a tensor network. The constructor RescaledArray(α, T) creates a rescaled array that equal to exp(α) * T.\n\n\n\n\n\n","category":"type"},{"location":"api/public/#TensorInference.TensorNetworkModel","page":"Public","title":"TensorInference.TensorNetworkModel","text":"struct TensorNetworkModel{LT, ET, MT<:AbstractArray}\n\nProbabilistic modeling with a tensor network.\n\nFields\n\nvars are the degrees of freedom in the tensor network.\ncode is the tensor network contraction pattern.\ntensors are the tensors fed into the tensor network.\nevidence is a dictionary used to specify degrees of freedom that are fixed to certain values.\n\n\n\n\n\n","category":"type"},{"location":"api/public/#TensorInference.ArtifactProblemSpec","page":"Public","title":"TensorInference.ArtifactProblemSpec","text":"struct ArtifactProblemSpec\n\nSpecify the UAI models from the artifacts. It can be used as the input of read_model.\n\nFields\n\nartifact_path::String\ntask::String\nproblem_set::String\nproblem_id::Int64\n\n\n\n\n\n","category":"type"},{"location":"api/public/#TensorInference.UAIModel","page":"Public","title":"TensorInference.UAIModel","text":"struct UAIModel{ET, FT<:(TensorInference.Factor{ET})}\n\nFields\n\nnvars is the number of variables,\nnclique is the number of cliques,\ncards is a vector of cardinalities for variables,\nfactors is a vector of factors,\n\n\n\n\n\n","category":"type"},{"location":"api/public/#Functions","page":"Public","title":"Functions","text":"","category":"section"},{"location":"api/public/","page":"Public","title":"Public","text":"contraction_complexity\nget_cards\nget_vars\nlog_probability\nmarginals\nmaximum_logp\nmost_probable_config\nprobability\ndataset_from_artifact\nproblem_from_artifact\nread_model\nread_evidence\nread_solution\nread_queryvars\nread_model_file\nread_evidence_file\nread_td_file\nsample","category":"page"},{"location":"api/public/#OMEinsumContractionOrders.contraction_complexity","page":"Public","title":"OMEinsumContractionOrders.contraction_complexity","text":"contraction_complexity(tensor_network)\n\nReturns the contraction complexity of a tensor newtork model.\n\n\n\n\n\ncontraction_complexity(eincode, size_dict) -> ContractionComplexity\n\nReturns the time, space and read-write complexity of the einsum contraction. The returned object contains 3 fields:\n\ntime complexity tc defined as log2(number of element-wise multiplications).\nspace complexity sc defined as log2(size of the maximum intermediate tensor).\nread-write complexity rwc defined as log2(the number of read-write operations).\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.get_cards","page":"Public","title":"TensorInference.get_cards","text":"get_cards(tn::TensorNetworkModel; fixedisone) -> Vector\n\n\nGet the cardinalities of variables in this tensor network.\n\n\n\n\n\nget_cards(mmap::MMAPModel; fixedisone) -> Vector\n\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.get_vars","page":"Public","title":"TensorInference.get_vars","text":"get_vars(tn::TensorNetworkModel) -> Vector\n\n\nGet the variables in this tensor network, they are also known as legs, labels, or degree of freedoms.\n\n\n\n\n\nget_vars(mmap::MMAPModel) -> Vector\n\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.log_probability","page":"Public","title":"TensorInference.log_probability","text":"log_probability(\n    tn::TensorNetworkModel,\n    config::Union{Dict, AbstractVector}\n) -> Real\n\n\nEvaluate the log probability of config.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.marginals","page":"Public","title":"TensorInference.marginals","text":"marginals(\n    tn::TensorNetworkModel;\n    usecuda,\n    rescale\n) -> Vector\n\n\nReturns the marginal probability distribution of variables. One can use get_vars(tn) to get the full list of variables in this tensor network.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.maximum_logp","page":"Public","title":"TensorInference.maximum_logp","text":"maximum_logp(\n    tn::TensorNetworkModel;\n    usecuda\n) -> AbstractArray{<:Real}\n\n\nReturns an output array containing largest log-probabilities.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.most_probable_config","page":"Public","title":"TensorInference.most_probable_config","text":"most_probable_config(\n    tn::TensorNetworkModel;\n    usecuda\n) -> Tuple{Real, Vector}\n\n\nReturns the largest log-probability and the most probable configuration.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.probability","page":"Public","title":"TensorInference.probability","text":"probability(\n    tn::TensorNetworkModel;\n    usecuda,\n    rescale\n) -> AbstractArray\n\n\nContract the tensor network and return a probability array with its rank specified in the contraction code tn.code. The returned array may not be l1-normalized even if the total probability is l1-normalized, because the evidence tn.evidence may not be empty.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.dataset_from_artifact","page":"Public","title":"TensorInference.dataset_from_artifact","text":"dataset_from_artifact(\n    artifact_name::AbstractString\n) -> Dict{String, Dict{String, Dict{Int64, ArtifactProblemSpec}}}\n\n\nHelper function that captures the problem names that belong to problem_set for the given task.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.problem_from_artifact","page":"Public","title":"TensorInference.problem_from_artifact","text":"problem_from_artifact(\n    artifact_name::String,\n    task::String,\n    problem_set::String,\n    problem_id::Int64\n) -> ArtifactProblemSpec\n\n\nGet artifact from artifact name, task name, problem set name and problem id.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_model","page":"Public","title":"TensorInference.read_model","text":"read_model(problem::ArtifactProblemSpec; eltype) -> UAIModel\n\n\nRead an UAI model from an artifact.\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_evidence","page":"Public","title":"TensorInference.read_evidence","text":"read_evidence(\n    problem::ArtifactProblemSpec\n) -> Dict{Int64, Int64}\n\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_solution","page":"Public","title":"TensorInference.read_solution","text":"read_solution(\n    problem::ArtifactProblemSpec;\n    factor_eltype\n) -> Any\n\n\nReturn the solution in the artifact.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_queryvars","page":"Public","title":"TensorInference.read_queryvars","text":"read_queryvars(\n    problem::ArtifactProblemSpec\n) -> Vector{Int64}\n\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_model_file","page":"Public","title":"TensorInference.read_model_file","text":"read_model_file(\n    model_filepath::AbstractString;\n    factor_eltype\n) -> UAIModel\n\n\nParse the problem instance found in model_filepath defined in the UAI model format. If the provided file path is empty, return nothing.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_evidence_file","page":"Public","title":"TensorInference.read_evidence_file","text":"read_evidence_file(\n    evidence_filepath::AbstractString\n) -> Tuple{Vector{Int64}, Vector{Int64}}\n\n\nReturn the observed variables and values in evidence_filepath. If the passed file path is an empty string, return empty vectors.\n\nThe UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.read_td_file","page":"Public","title":"TensorInference.read_td_file","text":"read_td_file(\n    td_filepath::AbstractString\n) -> Tuple{Int64, Int64, Int64, Vector{Vector{Int64}}, Vector{Vector{Int64}}}\n\n\nParse a tree decomposition instance described the PACE format.\n\nThe PACE file format is defined in: https://pacechallenge.org/2017/treewidth/\n\n\n\n\n\n","category":"function"},{"location":"api/public/#TensorInference.sample","page":"Public","title":"TensorInference.sample","text":"sample(\n    tn::TensorNetworkModel,\n    n::Int64;\n    usecuda\n) -> Matrix{Int64}\n\n\nGenerate samples from a tensor network based probabilistic model. Returns a vector of vector, each element being a configurations defined on get_vars(tn).\n\nArguments\n\ntn is the tensor network model.\nn is the number of samples to be returned.\n\n\n\n\n\n","category":"function"}]
}
