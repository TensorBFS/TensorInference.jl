<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Public · TensorInference.jl</title><meta name="title" content="Public · TensorInference.jl"/><meta property="og:title" content="Public · TensorInference.jl"/><meta property="twitter:title" content="Public · TensorInference.jl"/><meta name="description" content="Documentation for TensorInference.jl."/><meta property="og:description" content="Documentation for TensorInference.jl."/><meta property="twitter:description" content="Documentation for TensorInference.jl."/><meta property="og:url" content="https://TensorBFS.github.io/TensorInference.jl/api/public/"/><meta property="twitter:url" content="https://TensorBFS.github.io/TensorInference.jl/api/public/"/><link rel="canonical" href="https://TensorBFS.github.io/TensorInference.jl/api/public/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="TensorInference.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TensorInference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Background</span><ul><li><a class="tocitem" href="../../probabilistic-inference/">Probabilistic Inference</a></li><li><a class="tocitem" href="../../tensor-networks/">Tensor Networks</a></li><li><a class="tocitem" href="../../uai-file-formats/">UAI file formats</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples-overview/">Overview</a></li><li><a class="tocitem" href="../../generated/asia-network/main/">Asia Network</a></li><li><a class="tocitem" href="../../generated/hard-core-lattice-gas/main/">Hard-core Lattice Gas</a></li></ul></li><li><a class="tocitem" href="../../performance-evaluation/">Performance evaluation</a></li><li><a class="tocitem" href="../../generated/performance-tips/">Performance tips</a></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Public</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Modules"><span>Modules</span></a></li><li><a class="tocitem" href="#Types"><span>Types</span></a></li><li><a class="tocitem" href="#Functions"><span>Functions</span></a></li></ul></li><li><a class="tocitem" href="../internal/">Internal</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Public</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Public</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TensorBFS/TensorInference.jl/blob/main/docs/src/api/public.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Public-API"><a class="docs-heading-anchor" href="#Public-API">Public API</a><a id="Public-API-1"></a><a class="docs-heading-anchor-permalink" href="#Public-API" title="Permalink"></a></h1><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p><a href="#Modules">Modules</a></p><ul><li><a href="#TensorInference"><code>TensorInference</code></a></li></ul><p><a href="#Types">Types</a></p><ul><li><a href="#OMEinsumContractionOrders.GreedyMethod"><code>OMEinsumContractionOrders.GreedyMethod</code></a></li><li><a href="#OMEinsumContractionOrders.KaHyParBipartite"><code>OMEinsumContractionOrders.KaHyParBipartite</code></a></li><li><a href="#OMEinsumContractionOrders.MergeGreedy"><code>OMEinsumContractionOrders.MergeGreedy</code></a></li><li><a href="#OMEinsumContractionOrders.MergeVectors"><code>OMEinsumContractionOrders.MergeVectors</code></a></li><li><a href="#OMEinsumContractionOrders.SABipartite"><code>OMEinsumContractionOrders.SABipartite</code></a></li><li><a href="#OMEinsumContractionOrders.TreeSA"><code>OMEinsumContractionOrders.TreeSA</code></a></li><li><a href="#TensorInference.ArtifactProblemSpec"><code>TensorInference.ArtifactProblemSpec</code></a></li><li><a href="#TensorInference.MMAPModel"><code>TensorInference.MMAPModel</code></a></li><li><a href="#TensorInference.RescaledArray"><code>TensorInference.RescaledArray</code></a></li><li><a href="#TensorInference.TensorNetworkModel"><code>TensorInference.TensorNetworkModel</code></a></li><li><a href="#TensorInference.UAIModel"><code>TensorInference.UAIModel</code></a></li></ul><p><a href="#Functions">Functions</a></p><ul><li><a href="#OMEinsumContractionOrders.contraction_complexity"><code>OMEinsumContractionOrders.contraction_complexity</code></a></li><li><a href="#TensorInference.dataset_from_artifact"><code>TensorInference.dataset_from_artifact</code></a></li><li><a href="#TensorInference.get_cards"><code>TensorInference.get_cards</code></a></li><li><a href="#TensorInference.get_vars"><code>TensorInference.get_vars</code></a></li><li><a href="#TensorInference.log_probability"><code>TensorInference.log_probability</code></a></li><li><a href="#TensorInference.marginals"><code>TensorInference.marginals</code></a></li><li><a href="#TensorInference.maximum_logp"><code>TensorInference.maximum_logp</code></a></li><li><a href="#TensorInference.most_probable_config"><code>TensorInference.most_probable_config</code></a></li><li><a href="#TensorInference.probability"><code>TensorInference.probability</code></a></li><li><a href="#TensorInference.problem_from_artifact"><code>TensorInference.problem_from_artifact</code></a></li><li><a href="#TensorInference.read_evidence"><code>TensorInference.read_evidence</code></a></li><li><a href="#TensorInference.read_evidence_file"><code>TensorInference.read_evidence_file</code></a></li><li><a href="#TensorInference.read_model"><code>TensorInference.read_model</code></a></li><li><a href="#TensorInference.read_model_file"><code>TensorInference.read_model_file</code></a></li><li><a href="#TensorInference.read_queryvars"><code>TensorInference.read_queryvars</code></a></li><li><a href="#TensorInference.read_solution"><code>TensorInference.read_solution</code></a></li><li><a href="#TensorInference.read_td_file"><code>TensorInference.read_td_file</code></a></li><li><a href="#TensorInference.sample"><code>TensorInference.sample</code></a></li><li><a href="#TensorInference.update_evidence!"><code>TensorInference.update_evidence!</code></a></li><li><a href="#TensorInference.update_temperature"><code>TensorInference.update_temperature</code></a></li></ul><h2 id="Modules"><a class="docs-heading-anchor" href="#Modules">Modules</a><a id="Modules-1"></a><a class="docs-heading-anchor-permalink" href="#Modules" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference" href="#TensorInference"><code>TensorInference</code></a> — <span class="docstring-category">Module</span></header><section><div><p>Main module for <code>TensorInference.jl</code> – A toolbox for probabilistic inference using contraction of tensor networks.</p><p><strong>Exports</strong></p><ul><li><a href="#TensorInference.ArtifactProblemSpec"><code>ArtifactProblemSpec</code></a></li><li><a href="#OMEinsumContractionOrders.GreedyMethod"><code>GreedyMethod</code></a></li><li><a href="#OMEinsumContractionOrders.KaHyParBipartite"><code>KaHyParBipartite</code></a></li><li><a href="#TensorInference.MMAPModel"><code>MMAPModel</code></a></li><li><a href="#OMEinsumContractionOrders.MergeGreedy"><code>MergeGreedy</code></a></li><li><a href="#OMEinsumContractionOrders.MergeVectors"><code>MergeVectors</code></a></li><li><a href="#TensorInference.RescaledArray"><code>RescaledArray</code></a></li><li><a href="#OMEinsumContractionOrders.SABipartite"><code>SABipartite</code></a></li><li><a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a></li><li><a href="#OMEinsumContractionOrders.TreeSA"><code>TreeSA</code></a></li><li><a href="#TensorInference.UAIModel"><code>UAIModel</code></a></li><li><a href="#OMEinsumContractionOrders.contraction_complexity"><code>contraction_complexity</code></a></li><li><a href="#TensorInference.dataset_from_artifact"><code>dataset_from_artifact</code></a></li><li><a href="#TensorInference.get_cards"><code>get_cards</code></a></li><li><a href="#TensorInference.get_vars"><code>get_vars</code></a></li><li><a href="#TensorInference.log_probability"><code>log_probability</code></a></li><li><a href="#TensorInference.marginals"><code>marginals</code></a></li><li><a href="#TensorInference.maximum_logp"><code>maximum_logp</code></a></li><li><a href="#TensorInference.most_probable_config"><code>most_probable_config</code></a></li><li><a href="#TensorInference.probability"><code>probability</code></a></li><li><a href="#TensorInference.problem_from_artifact"><code>problem_from_artifact</code></a></li><li><a href="#TensorInference.read_evidence"><code>read_evidence</code></a></li><li><a href="#TensorInference.read_evidence_file"><code>read_evidence_file</code></a></li><li><a href="#TensorInference.read_model"><code>read_model</code></a></li><li><a href="#TensorInference.read_model_file"><code>read_model_file</code></a></li><li><a href="#TensorInference.read_queryvars"><code>read_queryvars</code></a></li><li><a href="#TensorInference.read_solution"><code>read_solution</code></a></li><li><a href="#TensorInference.read_td_file"><code>read_td_file</code></a></li><li><a href="#TensorInference.sample"><code>sample</code></a></li><li><a href="#TensorInference.update_evidence!"><code>update_evidence!</code></a></li><li><a href="#TensorInference.update_temperature"><code>update_temperature</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/TensorInference.jl#L1-L7">source</a></section></article><h2 id="Types"><a class="docs-heading-anchor" href="#Types">Types</a><a id="Types-1"></a><a class="docs-heading-anchor-permalink" href="#Types" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.GreedyMethod" href="#OMEinsumContractionOrders.GreedyMethod"><code>OMEinsumContractionOrders.GreedyMethod</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GreedyMethod{MT}
GreedyMethod(; method=MinSpaceOut(), nrepeat=10)</code></pre><p>The fast but poor greedy optimizer. Input arguments are</p><ul><li><code>method</code> is <code>MinSpaceDiff()</code> or <code>MinSpaceOut</code>.<ul><li><code>MinSpaceOut</code> choose one of the contraction that produces a minimum output tensor size,</li><li><code>MinSpaceDiff</code> choose one of the contraction that decrease the space most.</li></ul></li><li><code>nrepeat</code> is the number of repeatition, returns the best contraction order.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/greedy.jl#L295-L305">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.KaHyParBipartite" href="#OMEinsumContractionOrders.KaHyParBipartite"><code>OMEinsumContractionOrders.KaHyParBipartite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">KaHyParBipartite{RT,IT,GM}
KaHyParBipartite(; sc_target, imbalances=collect(0.0:0.005:0.8),
    max_group_size=40, greedy_config=GreedyMethod())</code></pre><p>Optimize the einsum code contraction order using the KaHyPar + Greedy approach. This program first recursively cuts the tensors into several groups using KaHyPar, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><ul><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>imbalances</code> is a KaHyPar parameter that controls the group sizes in hierarchical bipartition,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>greedy_config</code> is a greedy optimizer.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li><li><a href="https://arxiv.org/abs/2103.03074">Simulating the Sycamore quantum supremacy circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/kahypar.jl#L1-L19">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.MergeGreedy" href="#OMEinsumContractionOrders.MergeGreedy"><code>OMEinsumContractionOrders.MergeGreedy</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MergeGreedy &lt;: CodeSimplifier
MergeGreedy(; threshhold=-1e-12)</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges tensors greedily if the space complexity of merged tensors is reduced (difference smaller than the <code>threshhold</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/Core.jl#L83-L89">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.MergeVectors" href="#OMEinsumContractionOrders.MergeVectors"><code>OMEinsumContractionOrders.MergeVectors</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MergeVectors &lt;: CodeSimplifier
MergeVectors()</code></pre><p>Contraction code simplifier (in order to reduce the time of calling optimizers) that merges vectors to closest tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/Core.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.SABipartite" href="#OMEinsumContractionOrders.SABipartite"><code>OMEinsumContractionOrders.SABipartite</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SABipartite{RT,BT}
SABipartite(; sc_target=25, ntrials=50, βs=0.1:0.2:15.0, niters=1000
    max_group_size=40, greedy_config=GreedyMethod(), initializer=:random)</code></pre><p>Optimize the einsum code contraction order using the Simulated Annealing bipartition + Greedy approach. This program first recursively cuts the tensors into several groups using simulated annealing, with maximum group size specifed by <code>max_group_size</code> and maximum space complexity specified by <code>sc_target</code>, Then finds the contraction order inside each group with the greedy search algorithm. Other arguments are</p><ul><li><code>size_dict</code>, a dictionary that specifies leg dimensions,</li><li><code>sc_target</code> is the target space complexity, defined as <code>log2(number of elements in the largest tensor)</code>,</li><li><code>max_group_size</code> is the maximum size that allowed to used greedy search,</li><li><code>βs</code> is a list of inverse temperature <code>1/T</code>,</li><li><code>niters</code> is the number of iteration in each temperature,</li><li><code>ntrials</code> is the number of repetition (with different random seeds),</li><li><code>greedy_config</code> configures the greedy method,</li><li><code>initializer</code>, the partition configuration initializer, one can choose <code>:random</code> or <code>:greedy</code> (slow but better).</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2002.01935">Hyper-optimized tensor network contraction</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/sa.jl#L1-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.TreeSA" href="#OMEinsumContractionOrders.TreeSA"><code>OMEinsumContractionOrders.TreeSA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TreeSA{RT,IT,GM}
TreeSA(; sc_target=20, βs=collect(0.01:0.05:15), ntrials=10, niters=50,
    sc_weight=1.0, rw_weight=0.2, initializer=:greedy, greedy_config=GreedyMethod(; nrepeat=1))</code></pre><p>Optimize the einsum contraction pattern using the simulated annealing on tensor expression tree.</p><ul><li><code>sc_target</code> is the target space complexity,</li><li><code>ntrials</code>, <code>βs</code> and <code>niters</code> are annealing parameters, doing <code>ntrials</code> indepedent annealings, each has inverse tempteratures specified by <code>βs</code>, in each temperature, do <code>niters</code> updates of the tree.</li><li><code>sc_weight</code> is the relative importance factor of space complexity in the loss compared with the time complexity.</li><li><code>rw_weight</code> is the relative importance factor of memory read and write in the loss compared with the time complexity.</li><li><code>initializer</code> specifies how to determine the initial configuration, it can be <code>:greedy</code> or <code>:random</code>. If it is using <code>:greedy</code> method to generate the initial configuration, it also uses two extra arguments <code>greedy_method</code> and <code>greedy_nrepeat</code>.</li><li><code>nslices</code> is the number of sliced legs, default is 0.</li><li><code>fixed_slices</code> is a vector of sliced legs, default is <code>[]</code>.</li></ul><p><strong>References</strong></p><ul><li><a href="https://arxiv.org/abs/2108.05665">Recursive Multi-Tensor Contraction for XEB Verification of Quantum Circuits</a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/treesa.jl#L146-L163">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.MMAPModel" href="#TensorInference.MMAPModel"><code>TensorInference.MMAPModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct MMAPModel{LT, AT&lt;:AbstractArray}</code></pre><p>Computing the most likely assignment to the query variables,  Xₘ ⊆ X after marginalizing out the remaining variables Xₛ = X \ Xₘ.</p><p class="math-container">\[{\rm MMAP}(X_i|E=e) = \arg \max_{X_M} \sum_{X_S} \prod_{F} f(x_M, x_S, e)\]</p><p><strong>Fields</strong></p><ul><li><code>vars</code> is the query variables in the tensor network.</li><li><code>code</code> is the tropical tensor network contraction pattern.</li><li><code>tensors</code> is the tensors fed into the tensor network.</li><li><code>clusters</code> is the clusters, each element of this cluster is a <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a> instance for marginalizing certain variables.</li><li><code>evidence</code> is a dictionary to specifiy degree of freedoms fixed to certain values, which should not have overlap with the query variables.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/mmap.jl#L10">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.RescaledArray" href="#TensorInference.RescaledArray"><code>TensorInference.RescaledArray</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct RescaledArray{T, N, AT&lt;:AbstractArray{T, N}} &lt;: AbstractArray{T, N}</code></pre><pre><code class="nohighlight hljs">RescaledArray(α, T) -&gt; RescaledArray</code></pre><p>An array data type with a log-prefactor, and a l∞-normalized storage, i.e. the maximum element in a tensor is 1. This tensor type can avoid the potential underflow/overflow of numbers in a tensor network. The constructor <code>RescaledArray(α, T)</code> creates a rescaled array that equal to <code>exp(α) * T</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/RescaledArray.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.TensorNetworkModel" href="#TensorInference.TensorNetworkModel"><code>TensorInference.TensorNetworkModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct TensorNetworkModel{LT, ET, MT&lt;:AbstractArray}</code></pre><p>Probabilistic modeling with a tensor network.</p><p><strong>Fields</strong></p><ul><li><code>vars</code> are the degrees of freedom in the tensor network.</li><li><code>code</code> is the tensor network contraction pattern.</li><li><code>tensors</code> are the tensors fed into the tensor network, the leading tensors are unity tensors associated with <code>mars</code>.</li><li><code>evidence</code> is a dictionary used to specify degrees of freedom that are fixed to certain values.</li><li><code>mars</code> is a vector, each element is a vector of variables to compute marginal probabilities.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.ArtifactProblemSpec" href="#TensorInference.ArtifactProblemSpec"><code>TensorInference.ArtifactProblemSpec</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct ArtifactProblemSpec</code></pre><p>Specify the UAI models from the artifacts. It can be used as the input of <a href="#TensorInference.read_model"><code>read_model</code></a>.</p><p><strong>Fields</strong></p><ul><li><p><code>artifact_path::String</code></p></li><li><p><code>task::String</code></p></li><li><p><code>problem_set::String</code></p></li><li><p><code>problem_id::Int64</code></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L190">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.UAIModel" href="#TensorInference.UAIModel"><code>TensorInference.UAIModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct UAIModel{ET, FT&lt;:(TensorInference.Factor{ET})}</code></pre><p><strong>Fields</strong></p><ul><li><code>nvars</code> is the number of variables,</li><li><code>cards</code> is a vector of cardinalities for variables,</li><li><code>factors</code> is a vector of factors,</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L17">source</a></section></article><h2 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="OMEinsumContractionOrders.contraction_complexity" href="#OMEinsumContractionOrders.contraction_complexity"><code>OMEinsumContractionOrders.contraction_complexity</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">contraction_complexity(tensor_network)</code></pre><p>Returns the contraction complexity of a tensor newtork model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L245-L249">source</a></section><section><div><pre><code class="language-julia hljs">contraction_complexity(eincode, size_dict) -&gt; ContractionComplexity</code></pre><p>Returns the time, space and read-write complexity of the einsum contraction. The returned object contains 3 fields:</p><ul><li>time complexity <code>tc</code> defined as <code>log2(number of element-wise multiplications)</code>.</li><li>space complexity <code>sc</code> defined as <code>log2(size of the maximum intermediate tensor)</code>.</li><li>read-write complexity <code>rwc</code> defined as <code>log2(the number of read-write operations)</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/OMEinsumContractionOrders.jl/blob/v0.8.3/src/complexity.jl#L182-L190">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.get_cards" href="#TensorInference.get_cards"><code>TensorInference.get_cards</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_cards(tn::TensorNetworkModel; fixedisone) -&gt; Vector
</code></pre><p>Get the cardinalities of variables in this tensor network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L200">source</a></section><section><div><pre><code class="language-julia hljs">get_cards(mmap::MMAPModel; fixedisone) -&gt; Vector
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/mmap.jl#L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.get_vars" href="#TensorInference.get_vars"><code>TensorInference.get_vars</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">get_vars(tn::TensorNetworkModel) -&gt; Vector
</code></pre><p>Get the variables in this tensor network, they are also known as legs, labels, or degree of freedoms.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L193">source</a></section><section><div><pre><code class="language-julia hljs">get_vars(mmap::MMAPModel) -&gt; Vector
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/mmap.jl#L45">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.log_probability" href="#TensorInference.log_probability"><code>TensorInference.log_probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">log_probability(
    tn::TensorNetworkModel,
    config::Union{Dict, AbstractVector}
) -&gt; Real
</code></pre><p>Evaluate the log probability (or partition function) of <code>config</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L212">source</a></section><section><div><pre><code class="language-julia hljs">log_probability(
    tn::TensorNetworkModel;
    usecuda
) -&gt; AbstractArray
</code></pre><p>Evaluate the log probability (or partition function). It is the logged version of <a href="#TensorInference.probability"><code>probability</code></a>, which is less likely to overflow.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L221">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.marginals" href="#TensorInference.marginals"><code>TensorInference.marginals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">marginals(
    tn::TensorNetworkModel;
    usecuda,
    rescale
) -&gt; Dict{Vector{Int64}}
</code></pre><p>Queries the marginals of the variables in a <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a>. The function returns a dictionary, where the keys are the variables and the values are their respective marginals. A marginal is a probability distribution over a subset of variables, obtained by integrating or summing over the remaining variables in the model. By default, the function returns the marginals of all individual variables. To specify which marginal variables to query, set the <code>mars</code> field when constructing a <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a>. Note that the choice of marginal variables will affect the contraction order of the tensor network.</p><p><strong>Arguments</strong></p><ul><li><code>tn</code>: The <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a> to query.</li><li><code>usecuda</code>: Specifies whether to use CUDA for tensor contraction.</li><li><code>rescale</code>: Specifies whether to rescale the tensors during contraction.</li></ul><p><strong>Example</strong></p><p>The following example is taken from <a href="https://tensorbfs.github.io/TensorInference.jl/dev/generated/asia-network/main/"><code>examples/asia-network/main.jl</code></a>.</p><pre><code class="language-julia-repl hljs">julia&gt; model = read_model_file(pkgdir(TensorInference, &quot;examples&quot;, &quot;asia-network&quot;, &quot;model.uai&quot;));

julia&gt; tn = TensorNetworkModel(model; evidence=Dict(1=&gt;0))
TensorNetworkModel{Int64, DynamicNestedEinsum{Int64}, Array{Float64}}
variables: 1 (evidence → 0), 2, 3, 4, 5, 6, 7, 8
contraction time = 2^6.022, space = 2^2.0, read-write = 2^7.077

julia&gt; marginals(tn)
Dict{Vector{Int64}, Vector{Float64}} with 8 entries:
  [8] =&gt; [0.450138, 0.549863]
  [3] =&gt; [0.5, 0.5]
  [1] =&gt; [1.0]
  [5] =&gt; [0.45, 0.55]
  [4] =&gt; [0.055, 0.945]
  [6] =&gt; [0.10225, 0.89775]
  [7] =&gt; [0.145092, 0.854908]
  [2] =&gt; [0.05, 0.95]

julia&gt; tn2 = TensorNetworkModel(model; evidence=Dict(1=&gt;0), mars=[[2, 3], [3, 4]])
TensorNetworkModel{Int64, DynamicNestedEinsum{Int64}, Array{Float64}}
variables: 1 (evidence → 0), 2, 3, 4, 5, 6, 7, 8
contraction time = 2^7.781, space = 2^5.0, read-write = 2^8.443

julia&gt; marginals(tn2)
Dict{Vector{Int64}, Matrix{Float64}} with 2 entries:
  [2, 3] =&gt; [0.025 0.025; 0.475 0.475]
  [3, 4] =&gt; [0.05 0.45; 0.005 0.495]</code></pre><p>In this example, we first set the evidence for variable 1 to 0 and then query the marginals of all individual variables. The returned dictionary has keys that correspond to the queried variables and values that represent their marginals. These marginals are vectors, with each entry corresponding to the probability of the variable taking a specific value. In this example, the possible values are 0 or 1. For the evidence variable 1, the marginal is always [1.0] since its value is fixed at 0.</p><p>Next, we specify the marginal variables to query as variables 2 and 3, and variables 3 and 4, respectively. The joint marginals may or may not affect the contraction time and space. In this example, the contraction space complexity increases from 2^{2.0} to 2^{5.0}, and the contraction time complexity increases from 2^{5.977} to 2^{7.781}. The output marginals are the joint probabilities of the queried variables, represented by tensors.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/mar.jl#L124">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.maximum_logp" href="#TensorInference.maximum_logp"><code>TensorInference.maximum_logp</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">maximum_logp(
    tn::TensorNetworkModel;
    usecuda
) -&gt; AbstractArray{&lt;:Real}
</code></pre><p>Returns an output array containing largest log-probabilities.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/map.jl#L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.most_probable_config" href="#TensorInference.most_probable_config"><code>TensorInference.most_probable_config</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">most_probable_config(
    tn::TensorNetworkModel;
    usecuda
) -&gt; Tuple{Real, Vector}
</code></pre><p>Returns the largest log-probability and the most probable configuration.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/map.jl#L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.probability" href="#TensorInference.probability"><code>TensorInference.probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probability(
    tn::TensorNetworkModel;
    usecuda,
    rescale
) -&gt; AbstractArray
</code></pre><p>Contract the tensor network and return an array of probability of evidence. Precisely speaking, the return value is the partition function, which may not be l1-normalized.</p><p>If the <code>openvars</code> of the input tensor networks is zero, the array rank is zero. Otherwise, the return values corresponds to marginal probabilities.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L232">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.dataset_from_artifact" href="#TensorInference.dataset_from_artifact"><code>TensorInference.dataset_from_artifact</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">dataset_from_artifact(
    artifact_name::AbstractString
) -&gt; Dict{String, Dict{String, Dict{Int64, ArtifactProblemSpec}}}
</code></pre><p>Helper function that captures the problem names that belong to <code>problem_set</code> for the given task.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L274">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.problem_from_artifact" href="#TensorInference.problem_from_artifact"><code>TensorInference.problem_from_artifact</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">problem_from_artifact(
    artifact_name::String,
    task::String,
    problem_set::String,
    problem_id::Int64
) -&gt; ArtifactProblemSpec
</code></pre><p>Get artifact from artifact name, task name, problem set name and problem id.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L206">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_model" href="#TensorInference.read_model"><code>TensorInference.read_model</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_model(problem::ArtifactProblemSpec; eltype) -&gt; UAIModel
</code></pre><p>Read an UAI model from an artifact.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L217">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_evidence" href="#TensorInference.read_evidence"><code>TensorInference.read_evidence</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_evidence(
    problem::ArtifactProblemSpec
) -&gt; Dict{Int64, Int64}
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L255">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_solution" href="#TensorInference.read_solution"><code>TensorInference.read_solution</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_solution(
    problem::ArtifactProblemSpec;
    factor_eltype
) -&gt; Any
</code></pre><p>Return the solution in the artifact.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L227">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_queryvars" href="#TensorInference.read_queryvars"><code>TensorInference.read_queryvars</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_queryvars(
    problem::ArtifactProblemSpec
) -&gt; Vector{Int64}
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L265">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_model_file" href="#TensorInference.read_model_file"><code>TensorInference.read_model_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_model_file(
    model_filepath::AbstractString;
    factor_eltype
) -&gt; UAIModel
</code></pre><p>Parse the problem instance found in <code>model_filepath</code> defined in the UAI model format. If the provided file path is empty, return <code>nothing</code>.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_evidence_file" href="#TensorInference.read_evidence_file"><code>TensorInference.read_evidence_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_evidence_file(
    evidence_filepath::AbstractString
) -&gt; Tuple{Vector{Int64}, Vector{Int64}}
</code></pre><p>Return the observed variables and values in <code>evidence_filepath</code>. If the passed file path is an empty string, return empty vectors.</p><p>The UAI file formats are defined in: https://uaicompetition.github.io/uci-2022/file-formats/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.read_td_file" href="#TensorInference.read_td_file"><code>TensorInference.read_td_file</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">read_td_file(
    td_filepath::AbstractString
) -&gt; Tuple{Int64, Int64, Int64, Vector{Vector{Int64}}, Vector{Vector{Int64}}}
</code></pre><p>Parse a tree decomposition instance described the PACE format.</p><p>The PACE file format is defined in: https://pacechallenge.org/2017/treewidth/</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/utils.jl#L150">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.sample" href="#TensorInference.sample"><code>TensorInference.sample</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sample(
    tn::TensorNetworkModel,
    n::Int64;
    usecuda
) -&gt; TensorInference.Samples
</code></pre><p>Generate samples from a tensor network based probabilistic model. Returns a vector of vector, each element being a configurations defined on <code>get_vars(tn)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>tn</code> is the tensor network model.</li><li><code>n</code> is the number of samples to be returned.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/sampling.jl#L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.update_evidence!" href="#TensorInference.update_evidence!"><code>TensorInference.update_evidence!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_evidence!(
    tnet::TensorNetworkModel,
    evidence::Dict
) -&gt; TensorNetworkModel
</code></pre><p>Update the evidence of a tensor network model, without changing the set of observed variables!</p><p><strong>Arguments</strong></p><ul><li><code>tnet</code> is the <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a> instance.</li><li><code>evidence</code> is the new evidence, the keys must be a subset of existing evidence.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/Core.jl#L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="TensorInference.update_temperature" href="#TensorInference.update_temperature"><code>TensorInference.update_temperature</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_temperature(
    tnet::TensorNetworkModel,
    problem::GenericTensorNetworks.GraphProblem,
    β::Real
) -&gt; TensorNetworkModel
</code></pre><p>Update the temperature of a tensor network model. The program will regenerate tensors from the problem, without repeated optimizing the contraction order.</p><p><strong>Arguments</strong></p><ul><li><code>tnet</code> is the <a href="#TensorInference.TensorNetworkModel"><code>TensorNetworkModel</code></a> instance.</li><li><code>problem</code> is the target constraint satisfiability problem.</li><li><code>β</code> is the inverse temperature.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/TensorBFS/TensorInference.jl/blob/6fde0df198d8be45fad0e952aad484b76bd0166f/src/generictensornetworks.jl#L26">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../generated/performance-tips/">« Performance tips</a><a class="docs-footer-nextpage" href="../internal/">Internal »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Saturday 1 June 2024 16:59">Saturday 1 June 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
